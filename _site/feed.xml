<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-12-31T14:29:47-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sebastian Yang</title><subtitle>This is the personal website for Sebastian Yang aka 杨毓恺.</subtitle><entry><title type="html">Match-3 Siege</title><link href="http://localhost:4000/projects/2022/winter/Match3Shooter" rel="alternate" type="text/html" title="Match-3 Siege" /><published>2022-12-30T01:40:23-08:00</published><updated>2022-12-30T01:40:23-08:00</updated><id>http://localhost:4000/projects/2022/winter/Match3Shooter</id><content type="html" xml:base="http://localhost:4000/projects/2022/winter/Match3Shooter">&lt;p&gt;Match-3 games like Candy Crash are some of the most popular games on mobile, while shooter games like Call of Duty are some of the most popular games on PC.&lt;/p&gt;

&lt;p&gt;What if we combine the two?&lt;/p&gt;

&lt;p&gt;Introducing Match-3 Siege!&lt;/p&gt;

&lt;h2 id=&quot;how-does-it-work&quot;&gt;How does it work?&lt;/h2&gt;

&lt;p&gt;In this game, you’ll be part of either the attacking or defending team. The attackers must destroy all of the colored spheres on the field, while the defenders must protect them.&lt;/p&gt;

&lt;p&gt;To destroy the spheres, attackers must shoot and match three or more of the same color, while countering defenders’ fire.&lt;/p&gt;

&lt;p&gt;To defend the sphere, the defenders need to find and guard strategic positions to prevent match-3 to happen (e.g. blue blue red blue) while inserting a new sphere into the field every 30s to make it harder for the attackers. (e.g. blue yellow blue red blue)&lt;/p&gt;

&lt;p&gt;If the attackers succeed in destroying all the spheres before time runs out, they win! But if there are any spheres remaining at the end of the game, the defenders win.&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/saNxsox4Wz8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The video above is a single-player demo I made for this idea. Even though it’s against AI, you can already feel the intense and fast-path adrenaline rush caused by constantly switching between playing match-3 while fighting against enemies.&lt;/p&gt;

&lt;p&gt;I think this can be another game mode in addition to team deathmatch, search and destroy and battle royal. Let me know what you think!&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This is made independently by me with Unreal Engine 5.1 and C++. This is my first time making Unreal games with C++ and it has been a great learning experience! I used free 3D and animation assets and implemented these:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;animation blending using blendspace&lt;/li&gt;
  &lt;li&gt;input mapping for locomotion&lt;/li&gt;
  &lt;li&gt;AI bahavior tree and blackboard for enemies&lt;/li&gt;
  &lt;li&gt;hook up particles and sound for shooting&lt;/li&gt;
  &lt;li&gt;lose and win conditions&lt;/li&gt;
  &lt;li&gt;the match-3 systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PS: I created the icon of this page using text to image AI.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="Game_Development" /><summary type="html">Match-3 games like Candy Crash are some of the most popular games on mobile, while shooter games like Call of Duty are some of the most popular games on PC.</summary></entry><entry><title type="html">A Second Person VR Game</title><link href="http://localhost:4000/projects/2022/fall/SecondPerson" rel="alternate" type="text/html" title="A Second Person VR Game" /><published>2022-11-26T21:40:23-08:00</published><updated>2022-11-26T21:40:23-08:00</updated><id>http://localhost:4000/projects/2022/fall/SecondPerson</id><content type="html" xml:base="http://localhost:4000/projects/2022/fall/SecondPerson">&lt;p&gt;Have you ever played a second-person multiplayer VR shooting game? Me neither, so I made one over the Thanksgiving break.&lt;/p&gt;

&lt;p&gt;Well, we first need to figure out what is a second-person game.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In a first-person game, you control yourself through your own perspective – I’m going left, I’m going right.&lt;/li&gt;
  &lt;li&gt;In a third-person game, you control yourself through an external perspective – They go left, they go right.&lt;/li&gt;
  &lt;li&gt;So naturally, in a second-person game, you control yourself through the perspective of another character – You go left, you go right.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this game, there are two players and two guns on the table. The goal is very simple: whoever picks up the gun and shoots the other player first wins. But there’s one catch: it’s a second-person game – you are controlling yourself through the perspective of your opponent.&lt;/p&gt;

&lt;p&gt;What does that actually mean? In this clip, it may look like a normal first-person game but you are not controlling yourself – if you raise your VR controller, the character in front of you will raise their hand, not the character you are in the perspective of.&lt;/p&gt;

&lt;p&gt;Originally I thought this would be as if I’m controlling myself through a mirror, but in reality, it is much worse …&lt;/p&gt;

&lt;p&gt;You can try it out &lt;a href=&quot;https://github.com/SCP650/SecondPersonVRGame/releases/tag/v1&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/fCkHKXO1GiU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;main-takeaways&quot;&gt;Main Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;1-true-second-person-vr-games-are-bad&quot;&gt;1. True Second Person VR Games are BAD&lt;/h3&gt;

&lt;p&gt;To make a true second-person game meant you cannot control the camera, since the camera is technically on the head of another character who you don’t control – you just happen to look out from their perspective.&lt;/p&gt;

&lt;p&gt;What that means for VR is that when you move your head to look right, the view you are seeing is not moving, instead, you have to ask the other player to move their head to look right so that you can see what’s on the right.&lt;/p&gt;

&lt;p&gt;This also means if the other player moves their head randomly, their view is not going to be impacted (since your head is not moving), but your view will move randomly causing vertigo and dizziness.&lt;/p&gt;

&lt;h3 id=&quot;2-a-compatitive-game-become-cooperative-quickly&quot;&gt;2. A Compatitive Game Become Cooperative Quickly&lt;/h3&gt;

&lt;p&gt;Even though the goal of the game is to kill the other player, we quickly realize it’s not playable if we don’t cooperate.&lt;/p&gt;

&lt;p&gt;In the video, you can see we struggle to get our own character inside our view. This is because:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Player A can only see stuff from Player B’s perspective. So A needs to give B instructions to adjust A’s view.&lt;/li&gt;
  &lt;li&gt;But B doesn’t know what A is seeing (B can only see A’s perspective), so B doesn’t know many degrees they need to turn.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hence we end up spending the majority of the play time telling the other party how to move their head – “Can you look right?”,”Can you look left?” – which I guess makes this a successful second-person game..? but not an enjoyable game.&lt;/p&gt;

&lt;h3 id=&quot;3-player-will-instinctively-move-their-head-to-adjust-the-camera&quot;&gt;3. Player Will Instinctively Move Their Head to Adjust the Camera&lt;/h3&gt;

&lt;p&gt;One added difficulty I wasn’t expecting before was that when A wants to look left, A will not only give instructions to B to look left but also instinctively move their head to the left – this means it’s also disrupting B’s view.&lt;/p&gt;

&lt;p&gt;And then B’s view is disrupted, B will instinctively move their head in the opposite direction, further disrupting A’s view. This would create a compound effect what gets worse very quickly…&lt;/p&gt;

&lt;h2 id=&quot;some-thoughts&quot;&gt;Some Thoughts…&lt;/h2&gt;

&lt;p&gt;I started this project knowing a second-person VR game would be a bad idea. But my main goal is to figure out how to network a VR game, and I did end up with a multiplayer VR game so I consider this a success!&lt;/p&gt;

&lt;p&gt;Nonetheless, let this serve as a lesson to whoever comes after me that wants to make a second-person VR game. Unless you want to make major sacrifices (like in Trover Saves the Universe), a true second-person game is not a good idea.&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This is made independently by me with &lt;a href=&quot;https://assetstore.unity.com/packages/3d/props/interior/polygon-dining-room-199435&quot;&gt;free 3D assets&lt;/a&gt; from Asset Store, the Oculus Plugin, and the BNG Interaction Framework. It is networked using Normcore. This app is made in Unity with Oculus Quest 2. It can also run on a windows machine with Oculus Link.&lt;/p&gt;

&lt;p&gt;PS: I created the icon of this page using text to image AI.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><category term="Game_Development" /><summary type="html">Have you ever played a second-person multiplayer VR shooting game? Me neither, so I made one over the Thanksgiving break.</summary></entry><entry><title type="html">Earf</title><link href="http://localhost:4000/projects/2022/summer/earf" rel="alternate" type="text/html" title="Earf" /><published>2022-08-20T22:40:23-07:00</published><updated>2022-08-20T22:40:23-07:00</updated><id>http://localhost:4000/projects/2022/summer/earf</id><content type="html" xml:base="http://localhost:4000/projects/2022/summer/earf">&lt;p&gt;Enjoying pictures of Earth? Why not try Earf – the AR Planet Generator!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tap on the screen to generate gorgeous planets&lt;/li&gt;
  &lt;li&gt;Move your device around to view them up close&lt;/li&gt;
  &lt;li&gt;Simulate physics to see planets collide!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To download the full app: &lt;a href=&quot;https://apps.apple.com/us/app/earf-ar-planets/id1641207075&quot;&gt;Apple App Store&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/UuTJdkB-cac&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This app is made with Unity using AR Foundation. Each terrains is procedurally genearted using multiple layers of perlin noise. A custom shader is made to coloring the planets with random gradients based on the distance of each vertex to the center. It simulations physically (sorta) accurate gravitational force. And also has a random name generator to give your pet planets names!&lt;/p&gt;

&lt;h2 id=&quot;how-was-it-made&quot;&gt;How was it made?&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p1.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p1.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Starting with a blob&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p2.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p2.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Make it round&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p3.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p3.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Sprinkle some perlin noise&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p4.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p4.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Clamp the noise to make ocean surface&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p5.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p5.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Paint the mountains with a shader&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p6.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p6.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Paint the planet with a shader&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p7.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p7.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Paint the ocean depths with a shader&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p8.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p8.png&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Done!&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><summary type="html">Enjoying pictures of Earth? Why not try Earf – the AR Planet Generator!</summary></entry><entry><title type="html">Siggraph 2022 Day 2</title><link href="http://localhost:4000/blogs/2022/summer/Siggraph22_Part2" rel="alternate" type="text/html" title="Siggraph 2022 Day 2" /><published>2022-08-12T07:40:23-07:00</published><updated>2022-08-12T07:40:23-07:00</updated><id>http://localhost:4000/blogs/2022/summer/Siggraph22_Part2</id><content type="html" xml:base="http://localhost:4000/blogs/2022/summer/Siggraph22_Part2">&lt;p&gt;Hi all, welcome to my Siggraph series where I post the TLDR of the most memorable stuff I see at the conference.&lt;/p&gt;

&lt;p&gt;This started as some rambling notes I took during the conference, and I just cleaned it up a bit. It may not be the most accurate (especially the technical papers) but feel free to take a look!&lt;/p&gt;

&lt;h2 id=&quot;day-2-events-ive-attended&quot;&gt;Day 2 Events I’ve attended:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Tech Papers: &lt;strong&gt;Ray Tracing &amp;amp; Monte Carlo Methods&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Expo: &lt;strong&gt;Emerging Technologies&lt;/strong&gt; + &lt;strong&gt;Immersive Pavilion&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Presentation: &lt;strong&gt;Advances in Real-Time Rendering in Games: Part II&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Expo: Companies&lt;/li&gt;
  &lt;li&gt;Unreal Talk: &lt;strong&gt;Animating In-Engine - Real-Time Production Workflows&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Expo: Appy Hour&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;highlights&quot;&gt;Highlights&lt;/h2&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;immersive-pavilion&quot;&gt;Immersive Pavilion&lt;/h2&gt;

&lt;h3 id=&quot;a-vr-locomotion-method-that-kinda-solves-motion-sickness&quot;&gt;A VR Locomotion Method that (kinda) Solves Motion Sickness&lt;/h3&gt;

&lt;p&gt;What is it: The demo is called “&lt;strong&gt;HyperJumping&lt;/strong&gt;” by Bernhard E. Riecke. It has two parts: lean based locomotion and hyperjump.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lean-Based Locomotion&lt;/strong&gt;: instead of pushing a thumbstick, you have to physically lean forward to move forward. Since your body is actually leaning forward as your visual changes, it’s less dizzy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hyperjump&lt;/strong&gt;: when the user reached a max speed, it will automatically teleport the user for a segment, and then the user will continue to travel at max speed.&lt;/p&gt;

&lt;p&gt;Use case: if a person wants to travel long distances in VR, they don’t want to use smooth locomotion (which is dizzy) and don’t want to teleport (since they will miss the view), they will use lean-based movement + hyperjump.&lt;/p&gt;

&lt;p&gt;Sebastian’s Review: conceptually this is a very interesting idea — combining physical movement with smooth locomotion and teleportation, but in practice, when I tried the demo the Hyperjump(teleportation) feels scary — I would suddenly teleport to another place without any warning. I really like the idea and think further exploration is required.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;expo-companies&quot;&gt;Expo: Companies&lt;/h2&gt;

&lt;p&gt;I tried a ton of demos at the expo, these are the top most memorable three&lt;/p&gt;

&lt;h3 id=&quot;omniverse&quot;&gt;Omniverse&lt;/h3&gt;

&lt;p&gt;I was really really shocked when I saw a live demo of Nvidia’s Omniverse. The demo showcases a game development workflow of 3 people, using Maya, Unreal and Adobe Substance 3D respectively on their own laptops.&lt;/p&gt;

&lt;p&gt;With Omniverse, everything is synced in real-time bi-directionally: if a new car is added in Unreal’s scene, it will be reflected in Maya and Substance 3D instantly. Then the artist in Substance 3D will pain the car, the texture will show up instantly in Unreal and Maya.&lt;/p&gt;

&lt;p&gt;This workflow is very magical and can drastically increase a team’s collaboration efficiency. Under the hood, everything works because they are using Disney’s new and open Universal Scene Description (USD) format. 
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/siggraph22/omniverse.jpg&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/siggraph22/omniverse.jpg&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Omniverse Integarting 3 Different Workflow&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;h3 id=&quot;oppo-air-glass&quot;&gt;Oppo Air glass&lt;/h3&gt;

&lt;p&gt;I tried Oppo’s Air glass, which is an extension screen you can attach to any glasses. It can display information like weather, messages and live translation.&lt;/p&gt;

&lt;p&gt;In theory, it sounds very good, but when I tried it in practice, I need to constantly change my eye focus between the glass and the person I’m talking to in real life which result in fatigue very quickly. The major issue is that the info is not spatialized. Having a screen that constantly displays irrelevant info is also distracting. It’s a good tech demo but would need a lot more improvement to be consume-ready.&lt;/p&gt;

&lt;h3 id=&quot;stretchsense-gloves&quot;&gt;StretchSense Gloves&lt;/h3&gt;

&lt;p&gt;A current problem with optical hand tracking is that if the hand is obstructed, it can’t be tracked. StretchSense gloves managed to imbed a lot of senses in a normal looking glove, and send rotational information from each joint to their software, which will then convert the data to Unity/Unreal supported format.&lt;/p&gt;

&lt;p&gt;On the update, the glove feels comfortable and does hand tracking very feel. But it comes at a hefty~$5k. It’s a good mocap solution and for research use, but probably not for consumer tech.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;animating-in-engine---real-time-production-workflows&quot;&gt;Animating In-Engine - Real-Time Production Workflows&lt;/h2&gt;

&lt;p&gt;The folks at Epic Games showcased how you can create animations in-engineer without the need for professional software like Maya.&lt;/p&gt;

&lt;p&gt;In the demo, the speaker is able to copy parts of one animation (jumping) and paste them to another animation (moving forward), the final result is a person hopping forward.&lt;/p&gt;

&lt;p&gt;This is very impressive in that programmers can just download a few free mocap assets, and cut and paste different portions to combine to the desired motions. This makes prototyping ideas and making short video clips so much faster.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;tech-papers-ray-tracing--monte-carlo-methods&quot;&gt;Tech Papers: Ray Tracing &amp;amp; Monte Carlo Methods&lt;/h2&gt;

&lt;h3 id=&quot;r2e2-low-latency-path-tracing-of-terabyte-scale-scenes-using-thousands-of-cloud-cpus&quot;&gt;R2E2: Low-latency Path Tracing of Terabyte-scale Scenes Using Thousands of Cloud CPUs&lt;/h3&gt;

&lt;p&gt;Problem: if you need to render terabyte-scale scenes, and you don’t happen to own a super computer… you are out of luck&lt;/p&gt;

&lt;p&gt;Solution: Why now rent thousands of CPUs to run at the same time? That’s what the author did, live, at the presentation — he rented thousands of AWS E3 instances and rendered a path-traced picture of a terabyte scene in ~1 mins.&lt;/p&gt;

&lt;h3 id=&quot;generalized-resampled-importance-sampling-foundations-of-restir&quot;&gt;Generalized Resampled Importance Sampling: Foundations of ReSTIR&lt;/h3&gt;

&lt;p&gt;Problem: Traditional ray tracing is very costly and slow, it also requires multiple passes to generate a good image.&lt;/p&gt;

&lt;p&gt;Context: The ReSTIR approach - it reuses samples from previous frames to improve path distributions across frames (temporal reuse) and resample between this and nearby pixels (spatial reuse)&lt;/p&gt;

&lt;p&gt;Solution: Through some cool math and magic that I don’t fully understand, the author generalized the ReSTIR approach to work on any domains without the need to know the exact PDF&lt;/p&gt;

&lt;h3 id=&quot;regression-based-monte-carlo-integration&quot;&gt;Regression-based Monte Carlo Integration&lt;/h3&gt;

&lt;p&gt;Problem: Solving integration is a hard but common problem in graphics, e.g. to light up one pixel properly, we need to calculate the integral of all the light paths connecting the pixel to the light source.&lt;/p&gt;

&lt;p&gt;Context: Currently we mostly use Monte Carlo Integration, which randomly samples the function and averages those values to estimate the integral. However, this is only an estimate and has errors.&lt;/p&gt;

&lt;p&gt;Solutions: the author proposes a new estimator using regression function + residual, this estimator is provable better than Monte Carlo. Because in the worst case, the regression will be a constant, which will produce the same result as Monte Carlo.&lt;/p&gt;</content><author><name></name></author><summary type="html">Hi all, welcome to my Siggraph series where I post the TLDR of the most memorable stuff I see at the conference.</summary></entry><entry><title type="html">Lightly Heavy</title><link href="http://localhost:4000/projects/2022/spring/Heavy" rel="alternate" type="text/html" title="Lightly Heavy" /><published>2022-02-04T16:40:23-08:00</published><updated>2022-02-04T16:40:23-08:00</updated><id>http://localhost:4000/projects/2022/spring/Heavy</id><content type="html" xml:base="http://localhost:4000/projects/2022/spring/Heavy">&lt;p&gt;Have you ever wondered what it feels like to fly in space? Well, now you can. This virtual reality game allows you to simulate space combat like in the Ender’s Game anytime and anywhere.&lt;/p&gt;

&lt;p&gt;This app is built in 36 hours independently by Sebastian Yang with original music composed by William Ozeas. It is developed for HoyaHack and won &lt;strong&gt;the U.S. Space Force Award&lt;/strong&gt;. You can download it and try it out &lt;a href=&quot;https://github.com/SCP650/LightlyHeavy-UnityVR/releases&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/VyIAN2M-e8o&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;main-takeaways&quot;&gt;Main Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;1-lock-rotations-and-lower-the-speed&quot;&gt;1. Lock Rotations and Lower the Speed!&lt;/h3&gt;

&lt;p&gt;I always thought continuous movement and jumping up and down in VR are the dizziest. I was wrong. When I first develop the movement mechanics, I didn’t lock rotation meaning if the player used the booster on their right hand, instead of going straight forward, they will start spinning like crazy while moving forward.&lt;/p&gt;

&lt;p&gt;The first few seconds were fun - as the speed is still slow. But afterward, the dizziness became unbearable. The takeaway here is to lower the speed to avoid dizziness, especially for beginners.&lt;/p&gt;

&lt;h3 id=&quot;2-prioritize-before-acting&quot;&gt;2. Prioritize Before Acting&lt;/h3&gt;

&lt;p&gt;There are two major components to this project: the tutorial area (spaceship) and the combat zone (giant sphere). Most developers will probably start with the combat zone since it’s the bulk of the game. However, I decided to start with the tutorial area.&lt;/p&gt;

&lt;p&gt;This is because the combat zone is essentially the tutorial areas with procedural generation – both shared the same movement systems and enemies. If I don’t have time to develop a good pro-gen system, the player could still learn how to play the game and explore a single level - the spaceship. However, if I started with the combat zone and the pro-gen is not working, the player would not know what to do and killed by enemies instantly.&lt;/p&gt;

&lt;p&gt;Even though I managed to finish the pro-gen systems, this prioritization could’ve saved my project.&lt;/p&gt;

&lt;h3 id=&quot;3-its-dangerous-to-go-alone&quot;&gt;3. It’s Dangerous to Go Alone!&lt;/h3&gt;

&lt;p&gt;I intentionally made this a solo project because I want to test my ability. Even though I was happy with the result, it was not fun to do everything by myself. I would prefer the collaboration and delegation I did in &lt;a href=&quot;http://localhost:4000/projects/2021/fall/Haunted&quot;&gt;Haunted&lt;/a&gt;. If possible, don’t go alone!&lt;/p&gt;

&lt;h2 id=&quot;some-thoughts&quot;&gt;Some Thoughts…&lt;/h2&gt;

&lt;p&gt;I’m very proud of this project, especially with the execution. In 36 hours, I managed to develop a movement mechanic in zero-g, an extendable enemy class system, and a procedural generation system for levels. I also managed to design a tutorial area with 3D assets, a combat zone in Blender, and multiple GUI components. And everything was done in a virtual reality setting.&lt;/p&gt;

&lt;p&gt;This was by no means a perfect execution – the enemy AI needs a lot more work and there’s a lack of more enemy and weapon types. But I’m very pleased with what I ended up with - a replayable space combat VR game that is actually fun to play.&lt;/p&gt;

&lt;p&gt;Moreover, it also (kinda) fulfilled my childhood dream - going to space. The Ender’s Game is one of my favorite novel series and movies. Seeing the fight in a giant sphere in space really inspired and motivated me. (heck I even applied to many top aerospace engineering programs during college applications). This project intersects my high school passion in space with my college passion in the metaverse. So I’m really glad I got to do this.&lt;/p&gt;

&lt;p&gt;Finally, this project is also a testament to my growth. When I first started three years ago, I would’ve never thought I can pull something like this off. During the past three years, I’ve tried a lot, failed a lot, learned a lot, and kept repeating. It is truly pleasing to see oneself grow.&lt;/p&gt;

&lt;p&gt;Now that my college life is over, a new journey awaits.&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This is made independently by me with &lt;a href=&quot;https://assetstore.unity.com/packages/3d/environments/sci-fi/sci-fi-styled-modular-pack-82913&quot;&gt;free 3D assets&lt;/a&gt; from Asset Store, free skyboxes, the Oculus Plugin and the BNG Interaction Framework. This app is made in Unity with Oculus Quest 2. It can run on a windows machine with Oculus Link.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><category term="Game_Development" /><summary type="html">Have you ever wondered what it feels like to fly in space? Well, now you can. This virtual reality game allows you to simulate space combat like in the Ender’s Game anytime and anywhere.</summary></entry><entry><title type="html">Game Creation Society</title><link href="http://localhost:4000/projects/2021/fall/GCS" rel="alternate" type="text/html" title="Game Creation Society" /><published>2022-01-23T16:40:23-08:00</published><updated>2022-01-23T16:40:23-08:00</updated><id>http://localhost:4000/projects/2021/fall/GCS</id><content type="html" xml:base="http://localhost:4000/projects/2021/fall/GCS">&lt;p&gt;The Game Creation Society is a student-led game development club at Carnegie Mellon. I’m honored to be elected as President of the Game Creation Society in 2020. In the fall semester alone, we have 100+ active members making 9 games in parallel.&lt;/p&gt;

&lt;p&gt;I joined this club in my freshman year not knowing anything about game development. But my time at GCS has been exceptional, I learned so much, made so many games, and met so many cool people. Here are some notable accomplishments we achieved during my time as President.&lt;/p&gt;

&lt;h2 id=&quot;accomplishments&quot;&gt;Accomplishments&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Attendence&lt;/strong&gt;:We had a record turnout this year. At the start of the semester, we started with 250+ people attending our info session and booth showing interest to join and end up with 100+ people actually attending. By the end of the semester, we successfully released 8 games at Hunt Library.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;VR&lt;/strong&gt;: We purchased our first VR headset as a club and made two VR games in the semester after.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Unreal + Unity Stuco&lt;/strong&gt;: We offered the first Unreal Engine course at Carnegie Mellon and continued our existing Unity student-taught course.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Developer Fund&lt;/strong&gt;: We started a fund with a  few hundred dollars to support our developers&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GCS Library&lt;/strong&gt;: We started a collection of assets that can be shared with all our members.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: Our Discord server continues to grow, now we have almost 600 members on the server.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Industry Talks&lt;/strong&gt;: We continued to host great industry talks.
    &lt;ul&gt;
      &lt;li&gt;We hosted an info session with &lt;em&gt;Epic Games&lt;/em&gt; for internship opportunity&lt;/li&gt;
      &lt;li&gt;We have &lt;em&gt;Rockstar Games&lt;/em&gt; gave the opening speech at our Pitch Fair.&lt;/li&gt;
      &lt;li&gt;We also invited alumni to join us, including the Tech Lead at &lt;em&gt;Unity&lt;/em&gt;, the Manager of Production at &lt;em&gt;PlayStation Studios&lt;/em&gt;, and the Lead Character Artist at &lt;em&gt;Heart Machine&lt;/em&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Personally, during my three years at GCS, I’ve made six games including PC, Mobile and VR games.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
    &lt;a href=&quot;https://www.gamecreation.org&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
      
        &lt;img src=&quot; /images/projects/GCS/website.png&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Game Creation Society Website&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;h2 id=&quot;to-gcs-members&quot;&gt;To GCS Members&lt;/h2&gt;

&lt;p&gt;I’m very honored to lead the club in the past year. I want to thank all the execs, team leads, alumni, and most of all, our members for giving me such a great experience.  I’ve no doubt the incoming execs will lead the club to the next great chapter, especially with the help of each and every one of you!&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="Software_Engineer" /><category term="Game_Development" /><category term="Product_Project_Management" /><summary type="html">The Game Creation Society is a student-led game development club at Carnegie Mellon. I’m honored to be elected as President of the Game Creation Society in 2020. In the fall semester alone, we have 100+ active members making 9 games in parallel.</summary></entry><entry><title type="html">Bat and Monitors</title><link href="http://localhost:4000/projects/2022/spring/Monitors" rel="alternate" type="text/html" title="Bat and Monitors" /><published>2022-01-22T16:40:23-08:00</published><updated>2022-01-22T16:40:23-08:00</updated><id>http://localhost:4000/projects/2022/spring/Monitors</id><content type="html" xml:base="http://localhost:4000/projects/2022/spring/Monitors">&lt;p&gt;Have you ever felt exhausted after a long day of work? Wanting to find a safe and private place to let it all out? Well, now you can. This application allows you to release all your stress and anger whenever you want and wherever you are. This is a rage room in virtual reality that gives you a baseball bat, and a lot of monitors.&lt;/p&gt;

&lt;p&gt;This app is built in 23 hours independently by Sebastian Yang for µHacks and it is the &lt;strong&gt;2nd place winner&lt;/strong&gt;. You can download it &lt;a href=&quot;https://github.com/SCP650/RageRoom-UnityVR/releases&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/lErdRuNXWKY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;main-takeaways&quot;&gt;Main Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;1-a-well-scoped-project-is-very-important-for-hackathons&quot;&gt;1. A Well-Scoped project is Very Important for Hackathons.&lt;/h3&gt;

&lt;p&gt;In my previous hackathons, my team and I always over-scope and end up staying up late or not finishing all we wanted to do. This time I pick a very small scope, I ended finished the majority of the content on Saturday morning and have an entire afternoon to play with procedural generation.&lt;/p&gt;

&lt;h3 id=&quot;2-cheat-the-eyes-with-sound-effects&quot;&gt;2. Cheat the Eyes with Sound Effects&lt;/h3&gt;

&lt;p&gt;To properly shatter an object, I’ll have to use Bender to cut up the meshes and textures into smaller pieces. That’s a lot of work considering the number of objects I have. Luckily, I notice that people care more about the moment they hit the object than the actual shattered pieces of objects – especially the pieces that are smaller.&lt;/p&gt;

&lt;p&gt;So I ended up using particle systems to “fake” shattering for smaller objects like cups and pen holders. Coupled with a satisfying sound effect, it managed to fool people into thinking they actually shattered it. But if they look closer, they will notice all the pieces are just cubes&lt;/p&gt;

&lt;h3 id=&quot;3-always-back-up&quot;&gt;3. Always Back Up&lt;/h3&gt;

&lt;p&gt;I tend to use GitHub to do version control, however, committing assets from the Unity Assets Store is against the guideline. So I have to gitignore all those assets to keep my Github repo public. During my development, I made a lot of extensions based on store assets – creating new prefabs, extending code, etc. I even edited some assets directly. However, these edits are not tracked by GitHub.&lt;/p&gt;

&lt;p&gt;I ended up accidentally deleting all the store assets when merging branches and staring at an empty scene halfway through development – luckily I recovered everything from the recycling bin and I have intermediate builds I could always submit.&lt;/p&gt;

&lt;p&gt;However, in the future, if I have to gitignore important assets. I should not only make intermediate builds but also make a local copy of the entire project at each milestone.&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This is made independently by me with Unity’s free 3D Snaps Prototype assets, free skyboxes, the Oculus Plugin and the BNG Interaction Framework. This app is made in Unity with Oculus Quest 2. It can run on a windows machine AND standalone in an Oculus Quest 2 headset without the need of a PC.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><category term="Game_Development" /><summary type="html">Have you ever felt exhausted after a long day of work? Wanting to find a safe and private place to let it all out? Well, now you can. This application allows you to release all your stress and anger whenever you want and wherever you are. This is a rage room in virtual reality that gives you a baseball bat, and a lot of monitors.</summary></entry><entry><title type="html">Phight COVID</title><link href="http://localhost:4000/projects/2021/fall/Phight" rel="alternate" type="text/html" title="Phight COVID" /><published>2021-12-11T16:40:23-08:00</published><updated>2021-12-11T16:40:23-08:00</updated><id>http://localhost:4000/projects/2021/fall/Phight</id><content type="html" xml:base="http://localhost:4000/projects/2021/fall/Phight">&lt;p&gt;On March 11, 2020, the World Health Organization (WHO)’s declaration of COVID-19 as a pandemic caused widespread panic and alarm across the United States. One of the biggest shocks about the results of the pandemic was that the U.S. fared worse than other countries, “with more than 29 million cases and nearly 530,000 deaths” (Scientific American). As a result, there is an urgent need to understand the mistakes that were made which led to where we are today. This study is referenced on both &lt;a href=&quot;https://www.post-gazette.com/news/health/2021/12/12/Covid-mask-mandates-Pitt-CMU-research-delta/stories/202112080149&quot;&gt;Pittsburgh Post Gazette&lt;/a&gt; and &lt;a href=&quot;https://www.npr.org/sections/health-shots/2021/12/16/1064668750/state-mask-mandates-omicron&quot;&gt;NPR&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;research-questions&quot;&gt;Research Questions&lt;/h2&gt;
&lt;p&gt;We explore a variety of research question, each about the effectiveness of mask mandates at the state-level in the United States.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;How varied was mask mandate policy at the state-level?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How long does it take after a mask mandate intervention to see an impact on COVID cases?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Does effectiveness of mask mandates vary by season?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mask Mandates in the Delta Wave&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Were mask mandates in the Delta Wave effective?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How does vaccination rate interact with mask mandate effectiveness?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;full-interactive-report&quot;&gt;Full Interactive Report&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.stat.cmu.edu/capstoneresearch/490files/poster6.html&quot;&gt;linkt to report&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/4pJAN3VpOBE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;main-takeaways&quot;&gt;Main Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;1-coorelation--causation&quot;&gt;1. Coorelation != Causation&lt;/h3&gt;

&lt;p&gt;This may seem very obvious. However, the reality is we only have observational data but we want to draw a causal conclusion. What we end up doing is trying to account for confounding factors. One example is the graph my colleague Jimmy made where he compare the effectiveness of masks between states with similar vaccine rates. Even though we couldn’t account for every possible confound factor, we try to address the major and impactful ones.&lt;/p&gt;

&lt;h3 id=&quot;2-interactive-graphs-is-a-saver&quot;&gt;2. Interactive Graphs is a Saver&lt;/h3&gt;

&lt;p&gt;Graphs are good ways to visualize data but if it contains too much information then it becomes overwhelming. Interactive graphs are a balance between the two – it allows the readers to easily get the gist but also open to inspect individual data points in depth.&lt;/p&gt;

&lt;h3 id=&quot;3-data-reports-are-subject-to-manipulation&quot;&gt;3. Data Reports are Subject to Manipulation&lt;/h3&gt;

&lt;p&gt;In our research, we try out best to maintain objectivity. However, we can clearly see that it’s very easy for the researcher to manipulate the analysis so that they can see the results they want: e.g. using different success criteria, comparator, or calculation methods. In an academic research paper, this may be very apparent, but in a corporate setting where the people only skim the conclusion and the graph, it leaves a lot of room for manipulation. Hence, it’s advisable for PMs to understand how the data analysis is conducted to ensure it’s not intentionally or accidentally manipulated.&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;We utilized R with various packages including tidyverse, ggplot2, and plotly.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="Data_Analysis" /><summary type="html">On March 11, 2020, the World Health Organization (WHO)’s declaration of COVID-19 as a pandemic caused widespread panic and alarm across the United States. One of the biggest shocks about the results of the pandemic was that the U.S. fared worse than other countries, “with more than 29 million cases and nearly 530,000 deaths” (Scientific American). As a result, there is an urgent need to understand the mistakes that were made which led to where we are today. This study is referenced on both Pittsburgh Post Gazette and NPR.</summary></entry><entry><title type="html">Haunted VR</title><link href="http://localhost:4000/projects/2021/fall/Haunted" rel="alternate" type="text/html" title="Haunted VR" /><published>2021-12-11T16:40:23-08:00</published><updated>2021-12-11T16:40:23-08:00</updated><id>http://localhost:4000/projects/2021/fall/Haunted</id><content type="html" xml:base="http://localhost:4000/projects/2021/fall/Haunted">&lt;p&gt;Haunted is a VR horror game where the only enemy is yourself. In this game, there are no monsters or enemies that hurt you, instead, the only way to lose is if you got scared.&lt;/p&gt;

&lt;p&gt;You woke up in a completely dark house with only a candle in your hand. If you wave your hand too fast, the candle goes out, and game over. The game is consists of six rooms, each room has a unique set of mechanics that will be randomly activated. You need to reclaim three memory shards that are randomly scattered in some of the six rooms.&lt;/p&gt;

&lt;p&gt;The Haunted development team is the largest GCS team with 37 members working on it. My friend Woody McCoy co-lead the game with me. I’m very honored to be able to work with this awesome team of programmers, artiests, sound designers and writers in my last semester at CMU!&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/gQKX-AO6mgU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;inspiration&quot;&gt;Inspiration&lt;/h2&gt;

&lt;p&gt;When I was in high school I organized a 5-day summer camp. One of the events we came up with required one team to be the ghosts and the other to be the adventurer. The ghosts will have 10 mins to prep the classroom and find places to hide. The adventurers will each hold a stick with a golf ball on top. The ghosts will try to scare the adventurers when they are exporing the classroom. If the ghosts successfully scared the adventurers and the adventurers dropped the ball, adventurers lose.&lt;/p&gt;

&lt;p&gt;This VR game was inspired by this experience.&lt;/p&gt;

&lt;h2 id=&quot;art&quot;&gt;Art&lt;/h2&gt;
&lt;p&gt;The game needs to be realistic. But it’s unrealistic for us to create all the assets since we are all full-time students. Instead, we utilized assets store models for most of the interior (walls, floors, etc). We are fortunate to have 10+ artists on our team. So we retextured and created many 2D and 3D assets including painting, doors, dolls, sketches, spider webs, rats, etc. Our artists also designed the rooms and layout of the house.&lt;/p&gt;

&lt;h2 id=&quot;story&quot;&gt;Story&lt;/h2&gt;
&lt;p&gt;The game needs to have a deeper meaning than just being scary. So we managed to recruit a team of 4 writers to join our project. Each time the player picks up a memory shard, we will play a voice line that tells a story that happened in that room.&lt;/p&gt;

&lt;p&gt;The gist of the story is you are a victorian doctor that just found a miracle drug - Mercury. By giving it to and curing many patients, you became famous. But over time you realized people are dying from the drug, yet you are drowning in fame and money you kept selling it. The gameplay is the process of the doctor realizing what he had done. The game has a dark ending: to end the game, the player has to pick up the “miracle drug” and drink it themselves.&lt;/p&gt;

&lt;p&gt;This is one of the few GCS games that has a complete storyline. Our writers wrote and recorded all the voice lines in the game. Kudos to them!&lt;/p&gt;

&lt;h2 id=&quot;programming&quot;&gt;Programming&lt;/h2&gt;
&lt;p&gt;The game needs to be able to scale up easily: more rooms can be added easily, and each room can add more mechanics easily. To achieve this, the high-level architecture of our game looks like this: there are GameEvent objects that implement mechanics such as jump scare, skeleton follow you, etc. And are Room objects that decided which subsets of GameEvents will be enabled in this playthrough. And there is an Oastrator object that decided which subsets of rooms will have shard in this playthrough.&lt;/p&gt;

&lt;h2 id=&quot;sound&quot;&gt;Sound&lt;/h2&gt;

&lt;p&gt;To create the most immersive experience, we included much spatial audio and dynamic sound effects. One example is as the player wave the candle, they will hear random piano notes to indicate the fire is going down. As they wave faster, the piano notes will increase in speed and volume. There are also a lot of original sound effects thanks to our one and only William Ozeas.&lt;/p&gt;

&lt;h2 id=&quot;production&quot;&gt;Production&lt;/h2&gt;
&lt;p&gt;This is an overscored project with a huge team working on it. Thus, good project management is critical to the success of the game. I divided the projects into three phases. 
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/Haunted/timeline.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/Haunted/timeline.png&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
    &lt;br /&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;phase-1-invest-in-internal-tools---3-weeks&quot;&gt;Phase 1: Invest in Internal Tools - 3 Weeks&lt;/h3&gt;

&lt;p&gt;I’ve allocated three weeks for the first phase. The goal of this sprint is to create a library of tools for future use so we divided folks into teams by disciplines:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tech Team: develop extendable systems and modular reusable mechanics; beginners get familiar with Unity!&lt;/li&gt;
  &lt;li&gt;Art Team: make a demo room playable in VR&lt;/li&gt;
  &lt;li&gt;Story Team: main storyline, mini-stories, and settings&lt;/li&gt;
  &lt;li&gt;Audio Team: sample music and sound effects!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By the end of Phase 1, we finished the first room in the game - the Fourier. We showcased this room in the Game Creation Society Alpha.&lt;/p&gt;

&lt;h3 id=&quot;phase-2-room-development---4-weeks&quot;&gt;Phase 2: Room Development - 4 Weeks&lt;/h3&gt;

&lt;p&gt;In the second phase, we dive into developing the remaining rooms. I divided the teams into three “Room Teams” each team responsible for making a room (including art, programming, and story) in two weeks. The idea is people can use the mechanics developed in the previous sprint to make the rooms quickly.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Goal: 3 Teams, 2 Sprints, 6 Room&lt;/li&gt;
  &lt;li&gt;Each team has 2-3 Programmer + 1 Artist + 1 Writer + 1 Musician&lt;/li&gt;
  &lt;li&gt;Each team is responsible for a room every two week&lt;/li&gt;
  &lt;li&gt;4th week will be used for integration&lt;/li&gt;
  &lt;li&gt;Game should be playable and complete&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By the end of Phase 2, we had 4 playable rooms (Library, Study, Kitchen, and Fourier). My original goal is to finish the game by the end of the second phase. However, I also understand that was a reach so I left plenty of time in phase 3 to polish the game.&lt;/p&gt;

&lt;h3 id=&quot;phase-3-polish-debug-network---5-weeks&quot;&gt;Phase 3: Polish, Debug, Network - 5 Weeks&lt;/h3&gt;

&lt;p&gt;In the last phase, we spend the majority of the time polishing levels and making up some unfinished work from the previous sprint (bedroom and bathroom). Unfortunately but also expectedly, we have to ax the networking feature that allows one player to be the ghost to scare the other player.&lt;/p&gt;

&lt;p&gt;We wrapped up our game by the end of phase 3 and showcased our game at the GCS Release event.&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;The game is made with Unity 3.17 LTS with Github as version control. It is developed with and for Oculus Quest 2.&lt;/p&gt;

&lt;h2 id=&quot;future-plans&quot;&gt;Future Plans&lt;/h2&gt;

&lt;p&gt;If time permits, we wanted to add multiplayer networking into the game. One player will be a “ghost” and can toggle between being invisible and not while the other player is exploring the room finding memory shards. We also would like the game to be more interactive by making most if not all the small objects in the game grabble and throwable. 
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/Haunted/team.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/Haunted/team.png&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
    &lt;br /&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><category term="Highlights" /><category term="Game_Development" /><category term="Product_Project_Management" /><summary type="html">Haunted is a VR horror game where the only enemy is yourself. In this game, there are no monsters or enemies that hurt you, instead, the only way to lose is if you got scared.</summary></entry><entry><title type="html">Vinder</title><link href="http://localhost:4000/projects/2021/fall/Vinder" rel="alternate" type="text/html" title="Vinder" /><published>2021-10-04T17:40:23-07:00</published><updated>2021-10-04T17:40:23-07:00</updated><id>http://localhost:4000/projects/2021/fall/Vinder</id><content type="html" xml:base="http://localhost:4000/projects/2021/fall/Vinder">&lt;p&gt;Have you ever felt anxious before a date? Fearing it’s going to be super awkward? Or have you ever felt unsafe since you are meeting a complete stranger in person? We want to fix it.&lt;/p&gt;

&lt;p&gt;Why not have your first date in a safe and goofy environment, like in virtual reality? Our app Vinder envisions how dating will look like in the Metaverse. It’s a standalone app built for Oculus Quest. Using Vinder you can not only get matches but also have your first date in a fun interactive VR environment!&lt;/p&gt;

&lt;p&gt;This app is built in 24 hours independently by Sebastian Yang and Arshin Jain for HackCMU. It was the winner of the &lt;strong&gt;Facebook Metaverse Award&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;(Sorry for the poor video quality — when we finished editing it and we only have like 10 mins before the deadline and we never got a chance to edit it.)&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/sAMN1Jqq2WM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This app is made in Unity with Oculus Quest 2. It uses Photon server to facilitate live virtual meetings between matches. It can run on a windows machine AND standalone in an Oculus Quest 2 headset without the need of a PC.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><summary type="html">Have you ever felt anxious before a date? Fearing it’s going to be super awkward? Or have you ever felt unsafe since you are meeting a complete stranger in person? We want to fix it.</summary></entry></feed>