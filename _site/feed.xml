<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-04-28T10:51:37-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sebastian Yang</title><subtitle>This is the personal website for Sebastian Yang aka 杨毓恺.</subtitle><entry><title type="html">Silent Echo</title><link href="http://localhost:4000/projects/2023/fall/InterviewPrep" rel="alternate" type="text/html" title="Silent Echo" /><published>2023-11-09T21:40:23-08:00</published><updated>2023-11-09T21:40:23-08:00</updated><id>http://localhost:4000/projects/2023/fall/InterviewPrep</id><content type="html" xml:base="http://localhost:4000/projects/2023/fall/InterviewPrep">&lt;p&gt;Getting ready for job interviews can be really tough, especially if you’re a college student. It usually means asking friends for help, digging up good questions, and practicing by taking turns being the interviewer and the interviewee. But even after all that effort, the feedback you get might not be of high quality because, let’s face it, your friends are probably just as new to this as you are.&lt;/p&gt;

&lt;p&gt;Now, imagine if you could have a super experienced hiring manager right there in your living room to practice with. That’s the idea behind this innovative personal project. In this project, I wanted to learn how to merges the immersive experience of mixed reality with advanced AI technology to tackle real-life problems. If you’re curious to see how it works, feel free to check out the video below.&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/9tO_cyigUsg&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;main-takeaways&quot;&gt;Main Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;1-exploitation-vs-exploration--the-epsilon-greedy-strategy&quot;&gt;1. Exploitation vs Exploration – the Epsilon-Greedy Strategy&lt;/h3&gt;

&lt;p&gt;During the creation of our latest demo, I encountered a perplexing issue. In the Unity editor, everything functioned seamlessly, with every network request executing flawlessly. Yet, when making an Android build for the Quest 3, I was consistently thwarted by DNS resolution errors. Initially, I adopted an “exploitation” strategy: searching online for DNS resolution fixes, tweaking DNS servers, adjusting Android manifest network permissions, leveraging my accumulated knowledge to craft solutions based on available data. Nonetheless, this approach led me down a fruitless path, consuming an entire afternoon without resolving the issue.&lt;/p&gt;

&lt;p&gt;On the verge of capitulation, I shifted to an “exploration” mindset. I started aimlessly clicking through random menus in the Unity’s project settings. That’s when I made an expected discovery: 
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/InterviewPrep/BadUnityBad.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/InterviewPrep/BadUnityBad.png&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
    &lt;br /&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;
&lt;p&gt;&lt;br /&gt;
Buried within a labyrinth of menus (Project Setting -&amp;gt; XR Manager -&amp;gt; OpenXR -&amp;gt; Android -&amp;gt; All Features -&amp;gt; Meta Quest Support -&amp;gt; Settings Icon), I found an additional network toggle, mysteriously disabled the network by default and undocumented. It’s inconceivable for any platform to embed such a critical toggle so obscurely - imagine developing an iPhone app, meticulously setting camera permissions, only to find Apple concealed a disabling switch deep within seven layers of its interface.&lt;/p&gt;

&lt;p&gt;I ended up wasting seven exhausting hours on this bug. In hindsight, this reminds me of the Epsilon-Greedy Strategy. When debugging, instead of only selects the best-known action (exploitation), I should also occasionally chooses a random action (exploration) as sanity checks.&lt;/p&gt;

&lt;h3 id=&quot;2-unitys-openxr--meta-quest-3--a-tale-of-instability&quot;&gt;2. Unity’s OpenXR + Meta Quest 3 – A Tale of Instability&lt;/h3&gt;
&lt;p&gt;In this project, I wanted to delve into the intricacies of Unity’s OpenXR and XR Interaction Toolkit. Unfortunately, as of my experience, Unity’s implementation of OpenXR is in a state of considerable flux. Activating it within an existing project is akin to navigating a minefield; achieving mixed-reality passthrough is a Herculean task. Instead, my workaround was starting from Unity’s own sample OpenXR project, but this didn’t shield me from the previously mentioned network issues, nor did it ensure seamless operation on the Quest. Frustratingly, I often found myself trapped in a loop of forcibly uninstalling and reinstalling the app just to launch it.&lt;/p&gt;

&lt;p&gt;The root cause of these launch failures remains elusive, and I strongly suspect it’s not an issue with my code. There’s a telltale sign: the Unity icon doesn’t even display on the screen when the app stumbles with no error logs from my app. The most plausible explanation seems to be a discordance between OpenXR and the OS version of my Quest 3 - a mismatch that leaves much to be desired in terms of stability and integration.&lt;/p&gt;

&lt;p&gt;Consequently, I strongly recommend anyone who plans to develop exclusively for the Quest to opt for Meta’s XR UPM Package instead of OpenXR. This alternative seems to offer a more stable and streamlined path for development in the current landscape.&lt;/p&gt;

&lt;h3 id=&quot;3-ai-npc-in-mixed-reality--the-power-of-presence&quot;&gt;3. AI NPC in Mixed Reality – The Power of Presence&lt;/h3&gt;
&lt;p&gt;In this project, my objective was to explore the integration of Large Language Models (LLMs) with avatars, envisioning a scenario where an AI-driven expert interviewer could be virtually present in your living room to help with interview practice. The outcome, however, far surpassed my expectations. It’s hard to convey through video alone, but the experience of interacting with a life-sized humanoid that converses and responds to you is incredibly surreal. The avatar I employed wasn’t photorealistic, yet it still imparted a tangible sense of someone’s presence in my room.&lt;/p&gt;

&lt;p&gt;In the final demo video, I playfully responded to most of the interview questions to add a layer of interest, but in my initial takes, I found myself responding earnestly. The experience evoked the genuine stress of a real interview, complete with the pressure of someone watching and awaiting your responses. I felt an instinctive urge to answer promptly, mirroring the dynamics of an actual interview situation, where letting questions linger feels awkward. This venture into mixed reality with an AI NPC showcased the profound impact and potential of digital presence in our everyday interactions.&lt;/p&gt;

&lt;h2 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;/h2&gt;

&lt;p&gt;THIS PROJECT, CREATED AND DEVELOPED SOLELY BY SEBASTIAN YANG, IS INTENDED EXCLUSIVELY FOR PERSONAL EDUCATIONAL PURPOSES. ALL DEVELOPMENT AND TESTING HAVE BEEN CONDUCTED ON SEBASTIAN’S OWN PERSONAL EQUIPMENT. UNDER NO CIRCUMSTANCES SHALL THE SOURCE CODE OR THE APPLICATION ITSELF BE DISTRIBUTED, PUBLISHED, OR SOLD IN ANY FORM OR MANNER.&lt;/p&gt;

&lt;p&gt;NO ANIMALS HARMED IN THE MAKING OF THIS PROJECT.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><summary type="html">Getting ready for job interviews can be really tough, especially if you’re a college student. It usually means asking friends for help, digging up good questions, and practicing by taking turns being the interviewer and the interviewee. But even after all that effort, the feedback you get might not be of high quality because, let’s face it, your friends are probably just as new to this as you are.</summary></entry><entry><title type="html">TechCrunch Disrupt 2023</title><link href="http://localhost:4000/blogs/2023/summer/TCDisrupt" rel="alternate" type="text/html" title="TechCrunch Disrupt 2023" /><published>2023-09-22T07:40:23-07:00</published><updated>2023-09-22T07:40:23-07:00</updated><id>http://localhost:4000/blogs/2023/summer/TCDisrupt</id><content type="html" xml:base="http://localhost:4000/blogs/2023/summer/TCDisrupt">&lt;p&gt;I recently attended the TechCrunch Disrupt event from September 19 to 21, 2023. During these days, I had the opportunity to engage with and glean insights from numerous startup founders. In this article, I’ll highlight some of the intriguing startups I came across.&lt;/p&gt;

&lt;h2 id=&quot;yodayoda---live-street-view-data&quot;&gt;Yodayoda - Live Street View Data&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Street view data has significant value, particularly for industries like construction and tourism. However, data from sources like Google Maps can often be outdated. Currently, there’s no effective way to access the freshest street view data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Yodayoda incentivizes drivers to affix their phones to their car windshields while driving. This setup allows the camera to capture real-time street views paired with precise GPS locations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sebastian’s Thoughts&lt;/strong&gt;: I’m drawn to the concept of harnessing everyday vehicles to gather the most current data. However, I anticipate a few challenges:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Duplicates&lt;/strong&gt;: If multiple cars use this app and traverse the same route on a given day, Yodayoda would need to compensate all the drivers. This becomes costly if the subsequent data from other cars doesn’t offer new insights. If only the first driver gets paid, the compensation diminishes as the user base grows.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phone Accessibility&lt;/strong&gt;: Many rely on their phones for navigation. Mounting it on the windshield might hinder easy access, especially for those without integrated systems like Apple CarPlay. A better strategy might be partnering with dash cam manufacturers to harvest data directly.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Demand&lt;/strong&gt;: The market for real-time street views, especially on an hourly basis, might be limited. A more realistic demand might revolve around weekly updates. This could further reduce the potential earnings for participating drivers.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ilume---smart-dog-feeding&quot;&gt;ilume - Smart Dog Feeding&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: The quantity of food a dog requires varies greatly based on its breed and the amount of daily exercise it gets. Overfeeding can result in obesity, potentially reducing the dog’s lifespan.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: ilume offers a dual-component system: a step tracker that attaches to the dog’s collar and a bowl equipped with a weight sensor. Users input their dog’s food calorie density into an app. Daily, owners can view their pet’s activity levels. When feeding time arrives, the bowl signals when the right amount of food has been added.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sebastian’s Thoughts&lt;/strong&gt;: I’ve personally faced this dilemma. I own a sizable Labrador, and feeding him as per the recommendations on the dog food packaging (4 cups daily) resulted in noticeable weight gain within weeks. I adjusted his diet to roughly 3 cups daily, occasionally increasing the amount on particularly active days. This process involves a lot of guesswork, and I’m constantly uncertain if I’m overfeeding or underfeeding him.&lt;/p&gt;

&lt;p&gt;Potential challenges include:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Scientific Backing&lt;/strong&gt;: The primary hurdle for ilume is establishing a credible ML model that correlates dog activity with caloric needs. Solid scientific evidence is essential to validate their methodology.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diverse Feeding Styles&lt;/strong&gt;: Many dog owners occasionally treat their pets or feed them variable-calorie raw foods. Catering to this range of feeding habits could prove challenging.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;carrots--cake---learn-first-play-later&quot;&gt;Carrots &amp;amp; Cake - Learn First, Play Later&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: For numerous households, the iPad serves a dual purpose as both a learning and entertainment tool. But how can parents ensure their kids prioritize educational content over gaming?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Carrots &amp;amp; Cake is a parental control app that empowers parents to set content categories. For instance, children might need to engage in 15 minutes of Duolingo before being granted 30 minutes on Call of Duty Mobile.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sebastian’s Thoughts&lt;/strong&gt;: This app effectively identifies and addresses a specific user pain point.&lt;/p&gt;

&lt;p&gt;Yet, it’s not without potential pitfalls:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;No Unique Selling Proposition&lt;/strong&gt;: The primary distinction for this app lies in its use of the Screen Time API, a feature unknown to many developers. However, during Apple’s WWDC 2021 session titled “Meet the Screen Time API”, they introduced a similar application called “Homework” that mirrors Carrots &amp;amp; Cake’s functionality. The session serves as a step-by-step tutorial on how to create it.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pricing Challenges&lt;/strong&gt;: The founders are considering a subscription-based model. This might be unfeasible. Given the simplicity in replicating such an app, competitors could easily introduce free versions to the market.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;pilot---collaborative-trip-planning&quot;&gt;Pilot - Collaborative Trip Planning&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Organizing a trip involving multiple participants often becomes cumbersome through group chats or even using platforms like Google Docs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Pilot introduces a shared planning interface where users can intuitively drag and drop itinerary items, complemented by an adjacent map. Notably, it offers auto-generated itineraries and suggests top tourist spots for effortless incorporation into travel plans. Its partnership with Kayak further streamlines the process by allowing in-app bookings. Revenue is generated through affiliate link commissions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sebastian’s Thoughts&lt;/strong&gt;: This is an ingenious solution to a ubiquitous problem I’ve frequently faced. While I’ve yet to test the app, its success seems promising, given robust execution. The affiliate-based revenue model is both logical and scalable.&lt;/p&gt;

&lt;p&gt;The potential challenge might arise if giants like Expedia decide to mimic these features. However, since Pilot isn’t in direct contention with booking platforms but rather complements them, this seems less probable. Moreover, replicating such an interactive, collaborative tool isn’t a straightforward endeavor. Capitalizing on their pioneer status, Pilot could establish a robust market presence, making it daunting for newcomers. The primary concern might be the user acquisition cost, given the infrequency of travel for most individuals. However, this is surmountable with the right marketing strategies.&lt;/p&gt;

&lt;h2 id=&quot;hal51ai---3d-holograms-with-your-phone&quot;&gt;Hal51.ai - 3D Holograms with Your Phone&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: There’s a growing demand for affordable holographic displays.
&lt;strong&gt;Solution&lt;/strong&gt;: Hal51.ai offers an innovative box wherein users place their phones. Utilizing reflection techniques, it projects the phone’s screen content within the box, all at a price point below $100.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sebastian’s Thoughts&lt;/strong&gt;: This product was visually striking. At first glance, it genuinely appears as if a 3D entity is maneuvering inside the box. However, closer scrutiny reveals it’s merely a 2D projection. While its affordable price might make it a fun conversational piece for gatherings, its novelty is likely transient. Its long-term applicability seems limited, especially when compared to more advanced technologies like the looking glass.&lt;/p&gt;

&lt;h2 id=&quot;chatgpt-wrappers&quot;&gt;ChatGPT Wrappers&lt;/h2&gt;
&lt;p&gt;The event showcased an abundance of ChatGPT-wrapper startups, spanning domains from coding to cybersecurity, web development, legal assistance, HR, and more. While each had its nuances, a common thread was their low entry barrier. This could spell challenges, especially when established players begin embracing similar functionalities.&lt;/p&gt;</content><author><name></name></author><summary type="html">I recently attended the TechCrunch Disrupt event from September 19 to 21, 2023. During these days, I had the opportunity to engage with and glean insights from numerous startup founders. In this article, I’ll highlight some of the intriguing startups I came across.</summary></entry><entry><title type="html">Playing Reality</title><link href="http://localhost:4000/blogs/Principles" rel="alternate" type="text/html" title="Playing Reality" /><published>2023-09-22T07:40:23-07:00</published><updated>2023-09-22T07:40:23-07:00</updated><id>http://localhost:4000/blogs/Principles</id><content type="html" xml:base="http://localhost:4000/blogs/Principles">&lt;p&gt;In the journey of life, we often encounter wisdom that has the power to transform us. But it’s easy, too easy, to let these transformative insights slip away, simply because we fail to act upon them. So I began writing this guide as a personal side-quest to gather the lanterns of wisdom —- those enlightening insights from others that have illuminated my journey. And as life’s game unfolded, my own playthrough, though not without its trials, bore fruit. Friends, colleagues, even strangers began seeking these nuggets of wisdom. Their curiosity was the spark that turned this personal diary into a beacon for others.&lt;/p&gt;

&lt;p&gt;But tread lightly. These pages were crafted for my eyes, my interpretation of the game of life. They are not universal cheat codes but rather a collection of strategies that worked for me, in my unique circumstances. Viewer discretion is not just advised, it’s essential. Forge your own path, use these principles as a compass, not a map.&lt;/p&gt;

&lt;p&gt;This is a guide I wrote for myself, but now, it’s in your hands. Navigate wisely, and remember, this is not just about playing the game — it’s about changing it.&lt;/p&gt;

&lt;h2 class=&quot;no_toc&quot; id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h2&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#1-the-investment-mindset&quot; id=&quot;markdown-toc-1-the-investment-mindset&quot;&gt;1. The Investment Mindset&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#11-balancing-short-term-vs-long-term-positive-vs-negative-returns&quot; id=&quot;markdown-toc-11-balancing-short-term-vs-long-term-positive-vs-negative-returns&quot;&gt;1.1 Balancing Short-term vs Long-term, Positive vs Negative Returns&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#12-focus-on-investments-that-yield-long-term-dividends&quot; id=&quot;markdown-toc-12-focus-on-investments-that-yield-long-term-dividends&quot;&gt;1.2 Focus on Investments That Yield Long-term Dividends&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#13-embracing-protective-put-options&quot; id=&quot;markdown-toc-13-embracing-protective-put-options&quot;&gt;1.3 Embracing Protective Put Options&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#14-capitalizing-on-asymmetric-risk-reward&quot; id=&quot;markdown-toc-14-capitalizing-on-asymmetric-risk-reward&quot;&gt;1.4 Capitalizing on Asymmetric Risk-Reward&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#15-interchangeability-of-time-and-money&quot; id=&quot;markdown-toc-15-interchangeability-of-time-and-money&quot;&gt;1.5 Interchangeability of Time and Money&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#16-weighing-opportunity-cost&quot; id=&quot;markdown-toc-16-weighing-opportunity-cost&quot;&gt;1.6 Weighing Opportunity Cost&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-the-game-design-mindset&quot; id=&quot;markdown-toc-2-the-game-design-mindset&quot;&gt;2. The Game Design Mindset&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#21-the-setting-of-personal-goals&quot; id=&quot;markdown-toc-21-the-setting-of-personal-goals&quot;&gt;2.1 The Setting of Personal Goals&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#22-the-power-of-instant-feedback&quot; id=&quot;markdown-toc-22-the-power-of-instant-feedback&quot;&gt;2.2 The Power of Instant Feedback&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#23-the-conviction-of-success&quot; id=&quot;markdown-toc-23-the-conviction-of-success&quot;&gt;2.3 The Conviction of Success&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#24-the-power-of-rewarding-progress&quot; id=&quot;markdown-toc-24-the-power-of-rewarding-progress&quot;&gt;2.4 The Power of Rewarding Progress&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#25-the-power-of-time-constraints&quot; id=&quot;markdown-toc-25-the-power-of-time-constraints&quot;&gt;2.5 The Power of Time Constraints&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#26-the-power-of-setting-rules&quot; id=&quot;markdown-toc-26-the-power-of-setting-rules&quot;&gt;2.6 The Power of Setting Rules&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-the-business-strategy-mindset&quot; id=&quot;markdown-toc-3-the-business-strategy-mindset&quot;&gt;3. The Business Strategy Mindset&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-changing-the-game&quot; id=&quot;markdown-toc-4-changing-the-game&quot;&gt;4. Changing the game&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#0-misc&quot; id=&quot;markdown-toc-0-misc&quot;&gt;0. Misc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;1-the-investment-mindset&quot;&gt;1. The Investment Mindset&lt;/h2&gt;
&lt;p&gt;Every Action or Inaction is an Investment. Remember, you have only two resources at your disposal: time and money. Both are finite. You have merely 24 hours a day and a budget that’s not endless. Each decision you make, each action you take, is essentially an investment of these resources, with the expectation of a return, be it positive or negative. Take, for instance, the simple decision of dining out with friends. What’s the return you’re seeking? Is it the relaxation from socializing, or the opportunity to learn something new? Weigh the investment of your time and money against the potential return.&lt;/p&gt;

&lt;p&gt;This isn’t about forgoing fun; it’s about having a clear objective, even in choices as mundane as eating out. Avoid situations where you end up wasting resources —- like an expensive meal with an annoying friend who can’t stop talking about the new Tesla they leased. For every action you take, you should constantly ask yourself is this a worthy investment?&lt;/p&gt;

&lt;h3 id=&quot;11-balancing-short-term-vs-long-term-positive-vs-negative-returns&quot;&gt;1.1 Balancing Short-term vs Long-term, Positive vs Negative Returns&lt;/h3&gt;
&lt;p&gt;Investments don’t always yield immediate, positive returns. Their value often varies based on time. For example, an evening watching Netflix might offer short-term relaxation, but if it becomes a habit, it could lead to long-term stagnation. Conversely, relentlessly working every night might boost your career short-term, but could lead to burnout in the long-term. Striking a balance is key -— allocate time for relaxation and for work. It’s about recognizing the potential positive or negative returns of your actions and finding a harmony that suits your goals.&lt;/p&gt;

&lt;h3 id=&quot;12-focus-on-investments-that-yield-long-term-dividends&quot;&gt;1.2 Focus on Investments That Yield Long-term Dividends&lt;/h3&gt;
&lt;p&gt;Some endeavors may not offer immediate returns but can be tremendously beneficial in the long run. For instance, dedicating hours to perfect a personal website, showcasing detailed projects, might not seem fruitful immediately. However, it becomes a portfolio that impresses recruiters, investors, and hiring managers in the years to come. This is a single one-time investment that pays heavy dividends over many many years. Similar long-term investments include learning new skills, attending workshops, or presenting at conferences. These actions might not show immediate results, but over time, they accumulate and pay off significantly.&lt;/p&gt;

&lt;h3 id=&quot;13-embracing-protective-put-options&quot;&gt;1.3 Embracing Protective Put Options&lt;/h3&gt;
&lt;p&gt;Just like in financial markets, where traders use put options to minimize losses, you can apply a similar strategy in life. For instance, as I was nearing graduation, I applied to both master’s programs and job positions. The master’s program was my put option -— if I failed to land a desirable job, I could fall back on further education, preventing a worst-case scenario of starting at a less-than-ideal company. Similarly, while pursuing my passion in VR/AR, I also honed skills in iOS engineering as a safety net. The beauty of this approach is its flexibility; you can choose to exercise these put options or not based on your circumstances.&lt;/p&gt;

&lt;h3 id=&quot;14-capitalizing-on-asymmetric-risk-reward&quot;&gt;1.4 Capitalizing on Asymmetric Risk-Reward&lt;/h3&gt;
&lt;p&gt;Occasionally, you’ll encounter scenarios with minimal risk but significant potential rewards. A classic example is job applications. The downside is limited—your application might be ignored. But the upside can be tremendous, ranging from job offers to invaluable interview experience. In such scenarios, it pays to be aggressive. Consider outsourcing mundane tasks like job applications to virtual assistants. This leads us to the principle of interchaning time and money.&lt;/p&gt;

&lt;h3 id=&quot;15-interchangeability-of-time-and-money&quot;&gt;1.5 Interchangeability of Time and Money&lt;/h3&gt;
&lt;p&gt;Time is more precious than money. You can always make more money, but you can’t make more time. Sometimes, it’s prudent to spend money to save time. Many people make the mistake of trading their time for money in mundane jobs like driving Uber, not realizing they’re not developing any new skills or advancing their careers.&lt;/p&gt;

&lt;p&gt;On the other hand, choosing to fly instead of driving to a nearby city might cost more, but it saves precious hours. The decision between flying and driving boils down to what you value more — your time or your money. Similarly, you can easilly outsource mundane tasks like job applications to virtual assistants to save time.&lt;/p&gt;

&lt;p&gt;However, there’s an exception to this rule. If an activity brings you joy, it’s not necessarily a waste of time. For instance, I prefer taking the public transit to the airport to enjoy the scenic route, but I opt for a quicker Uber ride home after a tiring flight.&lt;/p&gt;

&lt;h3 id=&quot;16-weighing-opportunity-cost&quot;&gt;1.6 Weighing Opportunity Cost&lt;/h3&gt;
&lt;p&gt;In a world of limited resources, every decision carries an opportunity cost. This cost is the road not taken, the choice you forgo when you decide one way. It’s crucial to weigh this carefully. In making a choice, ask yourself what you’re giving up and whether the trade-off is worth it. This mindset will guide you to make more informed, strategic decisions.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/blog/PlayingReality/gamedesign.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/blog/PlayingReality/gamedesign.png&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
    &lt;br /&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-the-game-design-mindset&quot;&gt;2. The Game Design Mindset&lt;/h2&gt;

&lt;p&gt;Why do we play video games? At first glance, they seem illogical. Games asks us to do the same actions over and over again, each time imbuing them with a slightly different significance. Gaming is a voluntary attempt to overcome unnecessary obstacles. You don’t find zombies lurking in your garden, yet you willingly tackle these unnecessary obstacles in ‘Plants vs Zombies’ wave after wave. You aren’t in a battlefield, yet many invest countless hours disarming virtual bombs in ‘CS:GO’. Meanwhile, our real life is filled with its own set of essential and necessary tasks, from completing assignments to fulfilling work responsibilities. Yet, often, we find ourselves prioritizing virtual, unnecessary tasks in a game over work in real-life. Why is that?&lt;/p&gt;

&lt;p&gt;The answer lies in a simple truth – reality is boring.&lt;/p&gt;

&lt;p&gt;The solution? Equally straightforward –- let’s redesign our reality to make it fun.&lt;/p&gt;

&lt;h3 id=&quot;21-the-setting-of-personal-goals&quot;&gt;2.1 The Setting of Personal Goals&lt;/h3&gt;
&lt;p&gt;In video games, objectives are crystal clear. Take ‘PUBG’ – the goal is to be the last one standing. The path? Eliminate other players. In ‘Plants vs. Zombies’, it’s about keeping zombies at bay, achieved through strategic planting. These games offer clear, attainable goals, and every player knows exactly what needs to be done to win.&lt;/p&gt;

&lt;p&gt;But what about real life? Often, in the real world, goals are nebulous. Many wander without a clear direction, content in their current state, or lost in the ambiguity of their aspirations. In real life, unlike in games, we don’t have predefined goals or explicit instructions.&lt;/p&gt;

&lt;p&gt;This is where setting a personal goal becomes crucial. It’s not just about setting any goal, but one that resonates with you, that ignites your passion. In gaming, some gamers focus on kill count over accuracy, while others do the opposite. Similarly, in life, your goal should be deeply personal, be it short-term, long-term, or a dream that seems beyond reach. What matters is that it holds significance for you.&lt;/p&gt;

&lt;p&gt;Here’s a personal example: When I was preparing for the ACT in high school, I set my sights on scoring above 32. This wasn’t for my parents or to boost my college applications, but because a friend scored 32, and I wanted to beat him. That was my only motivation. But it was a goal that meant something to me. It was personal.&lt;/p&gt;

&lt;p&gt;That’s the crux of setting goals. Make them personal, make them yours, make them something you care about.&lt;/p&gt;

&lt;h3 id=&quot;22-the-power-of-instant-feedback&quot;&gt;2.2 The Power of Instant Feedback&lt;/h3&gt;
&lt;p&gt;In gaming, each action is met with immediate feedback. Consider a battle royale game like PUBG: every successful shot, every enemy eliminated, brings you closer to victory. In Plants vs. Zombies, each strategic plant placement visibly defends your home. Even mistakes are instructive — seeing sunflowers devoured by zombies teaches a valuable lesson in strategy. This immediate feedback loop constantly informs you whether you’re on the right track.&lt;/p&gt;

&lt;p&gt;But life doesn’t come with this built-in feedback system – we must create our own feedback mechanisms to gauge progress. Find the smallest action that will move you closer to you goal when done repeatedly, and create feedback mechanisms around it.&lt;/p&gt;

&lt;p&gt;Take my own journey preparing for the ACT as an example. The traditional approach involves months of memorization and practice, with feedback only coming in the form of the final test score. In my case, I designed a daily feedback system. I dedicated four hours each day to mock tests, meticulously tracking scores to measure my progress. 
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/blog/PlayingReality/act.jpeg&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/blog/PlayingReality/act.jpeg&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
    &lt;br /&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;
&lt;p&gt;&lt;br /&gt;
Each day, I saw the fruits of my labor. If my score improved, it fueled my motivation. If it dipped, it drove me to work harder. This was my version of gaming — each day was a level to conquer, each improvement a victory in itself. While others might have spent their afternoons on leisure, I was steadfast in my pursuit, knowing that every step took me closer to my goal. It was akin to honing your skills in a game like CS:GO — repetitive, yes, but undeniably rewarding.&lt;/p&gt;

&lt;p&gt;In the professional world, this might translate to seeking regular feedback from colleagues or benchmarking your weekly achievements. It’s about creating a system that continuously guides you towards your goals, just as in a game.&lt;/p&gt;

&lt;h3 id=&quot;23-the-conviction-of-success&quot;&gt;2.3 The Conviction of Success&lt;/h3&gt;
&lt;p&gt;In the gaming realm, success is not a matter of if, but when. This confidence stems not just from clear objectives or the consistent feedback, but from an underlying belief: game designers don’t craft unwinnable challenges. This inherent belief fuels the gamer’s confidence in eventual victory.&lt;/p&gt;

&lt;p&gt;Contrast this with reality. Our aspirations — be it entering an Ivy League university or climbing the corporate ladder — often face uncertain outcomes. Life doesn’t assure us of success. This uncertainty can erode our belief in achieving our dreams.&lt;/p&gt;

&lt;p&gt;Yet, consider why games captivate us, why we persist through repeated failures in level: it’s that unshakeable belief in eventual success. To translate this into reality, you must foster a similar belief. Under the feedback system you’ve established, every step, no matter how small, is progress towards your goals.&lt;/p&gt;

&lt;p&gt;Take coding, for instance. It encapsulates this philosophy perfectly:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Clear Goal: Designing a specific program.&lt;/li&gt;
  &lt;li&gt;Feedback Mechanism: Every run of the program offers immediate insights into the impact of the latest code.&lt;/li&gt;
  &lt;li&gt;Unwavering Belief: Success in programming is seen as a given; many have succeeded before, and so can you.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Achieving a coding milestone brings a rush akin to conquering a formidable boss in Dark Souls — a surge of pride and accomplishment. Yet, this triumph often leaves a void, propelling coders to seek out their next challenge. It’s this cycle of success and the pursuit of new goals that fuels what appears to be an addiction to coding.&lt;/p&gt;

&lt;p&gt;The aforementioned three steps are the easist way to get started. Once you get the hang of it, you can also try the advanced features below.&lt;/p&gt;

&lt;h3 id=&quot;24-the-power-of-rewarding-progress&quot;&gt;2.4 The Power of Rewarding Progress&lt;/h3&gt;
&lt;p&gt;In the realm of video games, in addition to instant feedback for every small action, every significant milestone brings with it a significant reward. Whether it’s skill points gained upon leveling up, a treasure box discovered at the end of a dungeon, or a bounty of experience points earned from vanquishing a formidable boss, each of these moments is not just a reward but a testament to the player’s skill and progress.&lt;/p&gt;

&lt;p&gt;Now, imagine applying this principle to our real lives. Break down your goals into tangible milestones and associate each with a meaningful reward. This could be anything from a relaxing weekend getaway to a luxurious celebration dinner. These rewards act as beacons, illuminating your journey and providing the motivation to strive for the next achievement.&lt;/p&gt;

&lt;p&gt;This strategy of pairing immediate feedback with significant rewards for each milestone can streamline the pursuit of goals. It turns the journey into a series of victories, each step bringing its own sense of accomplishment and pleasure. By adopting this approach, reaching your goals becomes not just feasible but enjoyable.&lt;/p&gt;

&lt;h3 id=&quot;25-the-power-of-time-constraints&quot;&gt;2.5 The Power of Time Constraints&lt;/h3&gt;
&lt;p&gt;When designing games, the countdown is a powerful tool. It injects a sense of urgency and focus into the gameplay. Think of those critical moments in a Call of Duty campaign, where you have just one minute to evacuate before the bomb detonates or to stop a missile launcher. This ticking clock heightens the player’s concentration and effectiveness, turning each second into a precious resource.&lt;/p&gt;

&lt;p&gt;Now, let’s apply this principle to real life, where it can yield remarkable results, especially when combined with rewards. During my college years, I usually finish my assignments ahead of time. I use this simple yet powerful strategy: set a fixed period, say four hours, to complete an assignment. I realized the faster I finish, the more time I have for leisure, like playing video games. This approach turns work and fun into a zero-sum game, fueling motivation to complete tasks not only quickly but also with high quality — because redoing means less leisure time.&lt;/p&gt;

&lt;p&gt;This method of using time constraints is about making efficiency a game, where the reward is your own time. It’s about transforming pressure into productivity, urgency into achievement.&lt;/p&gt;

&lt;h3 id=&quot;26-the-power-of-setting-rules&quot;&gt;2.6 The Power of Setting Rules&lt;/h3&gt;
&lt;p&gt;In video games, many rules may seem arbitrary yet are crucial — falling into water equals instant death, landing in a haystack from any height is safe, and invisible barriers confine players to a set area. However, these rules, sometimes born from development constraints, are essential in making the game functional and enjoyable.&lt;/p&gt;

&lt;p&gt;Now, let’s take this concept and apply it to our daily lives. Here, too, we can establish our own set of rules — ones that might seem unconventional to others but work perfectly for us. It’s about creating a personal code that guides and improves our daily lives. Envision these rules as invisible boundaries that, like in a game, you cannot breach.&lt;/p&gt;

&lt;p&gt;One effective rule I’ve practiced is coupling a less desirable but necessary task with a more enjoyable, optional one. For example, I only allow myself gaming time after hitting the gym. Or doing a pushup every time I grab a snack. These self-imposed regulations create a system of checks and balances that promotes a healthier, more productive lifestyle.&lt;/p&gt;

&lt;p&gt;The beauty of this approach is its flexibility. Your rules can be as unique as you are. Maybe it’s reading a few pages while waiting for code to compile, or making a new friend each week. The key is to craft rules that make sense to you, that help steer your actions towards your goals, just as game rules direct a player’s journey.&lt;/p&gt;

&lt;h2 id=&quot;3-the-business-strategy-mindset&quot;&gt;3. The Business Strategy Mindset&lt;/h2&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h2 id=&quot;4-changing-the-game&quot;&gt;4. Changing the game&lt;/h2&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h2 id=&quot;0-misc&quot;&gt;0. Misc&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;It’s never too late to be what you might have been.&lt;/li&gt;
  &lt;li&gt;If you’re the smartest person in the room, you’re in the wrong room.&lt;/li&gt;
  &lt;li&gt;If you’re not the smartest person in the room, ask yourself how you can learn from them and become the smartest. Because in the game of life, being second is just being the first loser.&lt;/li&gt;
  &lt;li&gt;We suffer more in our imagianations than in reality.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">In the journey of life, we often encounter wisdom that has the power to transform us. But it’s easy, too easy, to let these transformative insights slip away, simply because we fail to act upon them. So I began writing this guide as a personal side-quest to gather the lanterns of wisdom —- those enlightening insights from others that have illuminated my journey. And as life’s game unfolded, my own playthrough, though not without its trials, bore fruit. Friends, colleagues, even strangers began seeking these nuggets of wisdom. Their curiosity was the spark that turned this personal diary into a beacon for others.</summary></entry><entry><title type="html">Tiktok in AR/VR</title><link href="http://localhost:4000/blogs/2023/summer/Reimagine_TikTok" rel="alternate" type="text/html" title="Tiktok in AR/VR" /><published>2023-06-10T07:40:23-07:00</published><updated>2023-06-10T07:40:23-07:00</updated><id>http://localhost:4000/blogs/2023/summer/Reimagine_TikTok</id><content type="html" xml:base="http://localhost:4000/blogs/2023/summer/Reimagine_TikTok">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Welcome to the “Reimagine” series. In this series, I’ll pick from the Top 100 apps in the app stores and reimagine them as AR/VR apps in three-dimensional space.&lt;/p&gt;

&lt;p&gt;This article will explore TikTok. The simplest approach would be to project the 2D TikTok interface into a big screen in AR glasses for the user. This kind of application might appear in the next few years. However, I hope to break away from the two-dimensional space and re-examine TikTok from a three-dimensional perspective.&lt;/p&gt;

&lt;p&gt;For this imaginative exercise, let’s assume we have the perfect pair of AR glasses at our disposal. Our exploration will delve into three parts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What problem is it solving?&lt;/li&gt;
  &lt;li&gt;Why can AR/VR solve this problem better?&lt;/li&gt;
  &lt;li&gt;What would the 3D user experience be like?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-problem-is-it-solving&quot;&gt;What problem is it solving?&lt;/h2&gt;

&lt;p&gt;We can broadly categorize TikTok users into content creators and content viewers.&lt;/p&gt;

&lt;h3 id=&quot;viewers&quot;&gt;Viewers&lt;/h3&gt;
&lt;p&gt;Problem: Alleviating boredom&lt;/p&gt;

&lt;p&gt;Solution: By providing short video content, users can easily discover and filter content they are interested in for instant entertainment and enjoyment.&lt;/p&gt;

&lt;p&gt;Depending on the use case, we can further divide viewers into fragmentary time users and focused time users.&lt;/p&gt;

&lt;p&gt;Fragmentary time users: These users browse TikTok during short pockets of time in their life (like waiting for a bus, queuing, etc.). Notably, in these scenarios, users need to stay aware of their surroundings, for example, noticing when the bus arrives, whether they need to move forward, etc.&lt;/p&gt;

&lt;p&gt;Focused time users: These users browse TikTok during large blocks of free time (like before sleep, leisurely weekends, etc.). In these scenarios, users are typically in a comfortable environment, without the need to pay attention to changes around them. They can fully invest in consuming TikTok content.&lt;/p&gt;

&lt;h3 id=&quot;creators&quot;&gt;Creators&lt;/h3&gt;
&lt;p&gt;Problem: High cost of making long videos and the content’s low likelihood of being discovered by users&lt;/p&gt;

&lt;p&gt;Solution: By adopting the short video format, the cost of producing high-quality videos is reduced, and a special ranking algorithm increases the chances of videos becoming viral.&lt;/p&gt;

&lt;p&gt;Creators can be further divided into UGC (User Generated Content) creators and PGC (Professionally Generated Content) creators.&lt;/p&gt;

&lt;p&gt;UGC creators: These creators typically use the built-in camera on their phones to record everyday life, shoot dances, capture moments, or create interesting content with filters. Their main need is to be able to record life instantaneously and conveniently and to edit videos simply and quickly.&lt;/p&gt;

&lt;p&gt;PGC creators: They typically use professional microphones and cameras and may rely on external professional software for video editing, script design, and graphic design. Their main need is to produce high-quality content more conveniently and hope this content can be efficiently distributed to users through the platform.&lt;/p&gt;

&lt;p&gt;While TikTok has many other uses, such as live streaming e-commerce, brand promotion, AI-generated content, etc., due to space limitations, I’ll mainly focus on the four use cases mentioned above. One of TikTok’s strengths is its accurate recommendation algorithm, but since it is “invisible” backend work and unrelated to the user’s direct experience, this article will focus on aspects other than the recommendation algorithm.&lt;/p&gt;

&lt;h2 id=&quot;why-can-arvr-solve-these-problems-better&quot;&gt;Why can AR/VR solve these problems better?&lt;/h2&gt;

&lt;h3 id=&quot;meeting-the-demand-for-immersive-experiences&quot;&gt;Meeting the demand for immersive experiences&lt;/h3&gt;
&lt;p&gt;In the current 2D social media, users can only consume content through text, images, and videos. While these methods can effectively convey information, it can’t compete with 3D experiences in terms of immersion and authenticity.&lt;/p&gt;

&lt;p&gt;In the era of spatial computing, we can display three-dimensional models, 3D images and videos with depth perception, and even 3D scenes that can completely replace a user’s reality. These new forms of media won’t replace the old ones but will coexist with them, enriching our media ecosystem.&lt;/p&gt;

&lt;h3 id=&quot;breaking-the-limitations-of-interactivity&quot;&gt;Breaking the limitations of interactivity&lt;/h3&gt;
&lt;p&gt;The interactivity of 2D social media mainly takes the form of likes, repost, comments,  etc. However, in a 3D AR/VR environment, users can interact with content and other users in more intuitive and rich ways, such as moving directly in the 3D environment, manipulating objects, gesturing, etc.&lt;/p&gt;

&lt;h3 id=&quot;unlocking-the-space-for-creativity&quot;&gt;Unlocking the space for creativity&lt;/h3&gt;
&lt;p&gt;In a 2D environment, creators are limited to expressing themselves within a two-dimensional plane. However, in a 3D environment, they can create richer, more dimensional content. &lt;strong&gt;This means that TikTok could transition from a “short video” platform to a “short-form experiences” platform.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Creators will no longer be restricted to a fixed-size screen but will be able to create in a three-dimensional space. They can choose to only display 2D content in this space, mix 2D and 3D content, or completely showcase pure 3D scenes. In pure 3D scenes, creators can also choose whether to completely replace the user’s reality with virtual content or intertwine virtual content into the user’s reality.&lt;/p&gt;

&lt;h3 id=&quot;in-conclusion&quot;&gt;In conclusion&lt;/h3&gt;
&lt;p&gt;For content consumers, the existing TikTok already offers instant fun by combining video and music. However, in the future, TikTok can transport users into “short experiences” through various virtual scenes, providing unprecedented dopamine stimulation.&lt;/p&gt;

&lt;p&gt;For content creators, this three-dimensional creative space will attract more game developers and modelers to participate. The cost of creating “short experiences” will be much lower than developing a full game, undoubtedly sparking more innovation and creativity.&lt;/p&gt;

&lt;h2 id=&quot;what-would-the-user-experience-be-like&quot;&gt;What would the user experience be like?&lt;/h2&gt;

&lt;p&gt;Riker sat alone in the airport terminal, like an island in a sea of bustling travelers. He casually put on his AR glasses, selected the TikTok app, plunging into its mixed reality mode. He could see his surrandings as before but he just stepped into a new universe.&lt;/p&gt;

&lt;p&gt;In the narrow terminal aisle in front of Riker, two vivid virtual hip-hop dancers appeared, performing the latest dancing challenge.They may have been captured as 3D video thousands of miles away, yet their movements and smiles were rendered as vividly as if they were dancing in front of him. In this modern age, creating 3D videos and photos with AR glasses was as straightforward as shooting 2D videos with a smartphone. As the dancers grooved, 3D heart emojis were floating upwards behind them. Suddenly, one dancer slipped, faltering towards a passenger sitting opposite Riker. But the passenger remained oblivious, for the spectacle unfolded solely within Riker’s AR glasses. Riker let out a slight chuckle. Although he wasn’t a dance enthusiast, this novel experience still intrigued him. He formed his hand to a thumbs-up gesture. It was instantly recognized by the AR glasses, and one more heart emoji rose slowly behind the dancers.&lt;/p&gt;

&lt;p&gt;With a light swipe on his thigh, the next experience appeared before Riker’s eyes. It was a financial news segment. The news anchor, dressed in a blue suit, seemed to be standing in real life in front of Riker’s left side. To Riker’s right, a 2D stock price chart presented the falling shares of a sports shoe company, which later animated into a 3D chart that introduced a new parameter -— user complaint numbers. As the anchor narrated the company’s spiking complaint numbers, Riker was interacting with the 3D chart, exploring it from various angles.  At the end of the video, the chart morphed into the company’s logo, and a virtual basket of fresh tomatoes and a basket of roses appeared before Riker. The anchor encouraged viewers to vote whether they would continue to purchase the company’s sport shoes. Watching other tomatoes flying towards the company’s logo, Riker picked up a virtual tomato and threw it too. In this era, creating such 3D interactive experiences has become incredibly simple. A slew of entry-level 3D scene design software sprang up, allowing many creators to effortlessly make 3D interactive content.&lt;/p&gt;

&lt;p&gt;The boarding announcement echoed through the terminal. With a swift gesture, Riker confined the TikTok app to a space in his immediate right before rising to join the boarding queue. Standing in line, he could enjoy TikTok on his right while keeping an eye on the movement of the queue ahead.&lt;/p&gt;

&lt;p&gt;Having found his seat on the plane and fastened his seatbelt, Riker switched TikTok to immersive mode. In this mode, his surroundings were completely replaced by virtual environment, as if he had been teleported to another space. The first thing he saw was a cute golden retriever rolling on a sofa in front of him. This was a 3D video, and Riker felt as if he were sitting in that family’s living room, as if he could reach out and touch the fluffy belly of the dog. If this was in mixed reality mode, TikTok would automatically remove the living room background and only place the golden retriever in Riker’s real environment. But in immersive mode, Riker felt as if he had been transported directly into that family’s living room, totally immersed in their happy moments with the dog.&lt;/p&gt;

&lt;p&gt;In the next experience, a huge pair of sports shoes appeared before Riker. Against the deep black background, the shoes were spinning elegantly like a prized exhibit. Accompanied by a powerful narrative voice, Riker was guided to look at his feet and try the shoes in AR – it was a 3D advertisement. Noticing Riker didn’t try the AR fitting, virtual gestures appeared on both sides of the shoes indicating it could be interacted with. Curiously, Riker pinched and drag the shoes to magnify them, revealing their stunningly detailed textures. Riker thought the shoe looked familiar, it seemed to be the same pair the dancers in the previous video was wearing when they slipped. Without thinking deeper, Riker swiped his finger lightly, moving on to the next experience.&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;It’s worth mentioning that in today’s internet environment, due to bandwidth limitations, real-time downloading of large 3D scene files to create a smooth feed still presents challenges. But with the advent of the 5G era, everything could change. Under the speedy 5G network, real-time downloads of 10-20MB or even larger 3D scenes will become a breeze, just as it was once unimaginable for TikTok to play 5-6MB short videos smoothly in a 3G network environment.&lt;/p&gt;

&lt;p&gt;At the same time, 3D models and content will become as common and easy to obtain as pictures and videos today. In the future, creating a 3D model will be as simple as taking a photo - in fact, we can now create 3D models by scanning objects with a phone, a technology that will only become more convenient and popular in the future.&lt;/p&gt;

&lt;p&gt;Similarly, creating 3D experiences will be as easy to get started as video editing but with a high ceiling. Users can easily layout 3D items, animations, 3D videos, 2D pictures or videos with an editor, and control the order of play, spatial position, and size changes by adjusting the timeline.&lt;/p&gt;

&lt;p&gt;Going one step further, recording 3D videos or taking 3D photos will be as easy as creating 2D content. Once AR glasses become widespread, anyone can easily record life’s wonderful moments in 3D. It’s a new world filled with infinite possibilities and imagination, and we look forward to its arrival.&lt;/p&gt;

&lt;h2 id=&quot;closing&quot;&gt;Closing&lt;/h2&gt;

&lt;p&gt;I want to reiterate that all the views I share here are my own. These thoughts do not represent the positions of my company or employer, nor do they contain any confidential information. My sole aim is to stimulate imagination and enthusiasm for potential AR/VR applications, helping everyone better understand this new field full of unknowns and possibilities through my personal insights and observations.&lt;/p&gt;

&lt;p&gt;I am fully aware that although I’ve made thoughtful explorations, with technological advancements and the passage of time, my depiction of the future might prove incorrect. Looking back from the future, many of my views may seem naive. But that won’t dampen my passion and interest in this exploration. I believe that only through trial and error can we discover new possibilities and innovate better solutions.&lt;/p&gt;

&lt;p&gt;Finally, I hope this series will inspire you, and I also look forward to your sharing of ideas and observations.&lt;/p&gt;</content><author><name></name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Reimagine Series Prologue</title><link href="http://localhost:4000/blogs/2023/summer/Reimagine_Prologue" rel="alternate" type="text/html" title="Reimagine Series Prologue" /><published>2023-06-09T07:40:23-07:00</published><updated>2023-06-09T07:40:23-07:00</updated><id>http://localhost:4000/blogs/2023/summer/Reimagine_Prologue</id><content type="html" xml:base="http://localhost:4000/blogs/2023/summer/Reimagine_Prologue">&lt;h2 id=&quot;what-is-this-series-about&quot;&gt;What is this series about?&lt;/h2&gt;

&lt;p&gt;Welcome to the “Reimagine” series. In this series, I will select applications from the Top 100 in the app store and reimagine what they would be like in a three-dimensional space, as AR/VR software. We will no longer be confined to the two-dimensional interfaces of mobile phones and computers, but shift our focus towards the more tangible and realistic three-dimensional space provided by AR/VR.&lt;/p&gt;

&lt;h2 id=&quot;why-do-i-write-this-series&quot;&gt;Why do I write this series?&lt;/h2&gt;

&lt;p&gt;We can make two basic assumptions about the future of technology:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;People desire more natural and realistic ways of interaction.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Looking back over the past decade or so, it’s clear to see that from the text messages and emails of the 2G era to the pictures and voice messages of the 3G era, and then to the short videos and live broadcasts of the 4G era, the carriers of information flow are becoming increasingly enriched, presenting in ways that are closer to the real world.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As three-dimensional beings, humans naturally understand and accept three-dimensional content.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our everyday lives take place in three-dimensional space. In other words, we are inherently accustomed to interacting in three dimensions, not confined to two-dimensional screens.&lt;/p&gt;

&lt;p&gt;Based on these two assumptions, we have reason to believe that spatial computing brought about by AR/VR will be the next growth point in human technology.&lt;/p&gt;

&lt;p&gt;However, I found that many people’s thinking is still confined to a two-dimensional plane, and it’s hard to imagine what WeChat or Taobao would be like in three dimensions. Yet, the software on our phones satisfies various daily needs, which will still exist in the era of spatial computing. This implies that these apps on our phones need to be redesigned and implemented in a three-dimensional environment.&lt;/p&gt;

&lt;p&gt;Through this series, I hope to explore with you the possibilities of this new world and envision the various stunning applications that may appear in the future.&lt;/p&gt;

&lt;h2 id=&quot;how-will-i-appraoch-it&quot;&gt;How will I appraoch it?&lt;/h2&gt;

&lt;p&gt;To make this series more meaningful, I’ll undertake the following steps in my exploration:&lt;/p&gt;

&lt;p&gt;Firstly, we need to set up an ideal environment. Assume we already have an ideal AR headset: a comprehensive, smooth, and convenient device that seamlessly integrates virtual information into the real world, providing users with unprecedented interactive experiences.&lt;/p&gt;

&lt;p&gt;Under this premise, I’ll select a series of killer apps from the app store based on their ranking. These apps may include social, shopping, education, etc., all of which are favored by a broad user base due to their effectiveness in solving certain user needs.&lt;/p&gt;

&lt;p&gt;Then, I’ll apply the following three-step analysis to these apps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What problem is it solving?&lt;/li&gt;
  &lt;li&gt;Why can AR/VR solve this problem better?&lt;/li&gt;
  &lt;li&gt;What will the specific user experience be like?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Through these steps, I hope to spark our thinking about spatial computing and open our imagination to future technologies.&lt;/p&gt;

&lt;h2 id=&quot;closing&quot;&gt;Closing&lt;/h2&gt;

&lt;p&gt;At the start of this journey, I want to make it clear: all the views I share here are my own. These thoughts do not represent the positions of my company or employer, nor do they contain any confidential information. My sole aim is to stimulate imagination and enthusiasm for potential AR/VR applications, helping everyone better understand this new field full of unknowns and possibilities through my personal insights and observations.&lt;/p&gt;

&lt;p&gt;I am fully aware that although I’ve made thoughtful explorations, with technological advancements and the passage of time, my depiction of the future might prove incorrect. Looking back from the future, many of my views may seem naive. But that won’t dampen my passion and interest in this exploration. I believe that only through trial and error can we discover new possibilities and innovate better solutions.&lt;/p&gt;

&lt;p&gt;Finally, I hope this series will inspire you, and I also look forward to your sharing of ideas and observations.&lt;/p&gt;</content><author><name></name></author><summary type="html">What is this series about?</summary></entry><entry><title type="html">Vrlingo</title><link href="http://localhost:4000/projects/2022/fall/Vrlingo" rel="alternate" type="text/html" title="Vrlingo" /><published>2023-01-13T21:40:23-08:00</published><updated>2023-01-13T21:40:23-08:00</updated><id>http://localhost:4000/projects/2022/fall/Vrlingo</id><content type="html" xml:base="http://localhost:4000/projects/2022/fall/Vrlingo">&lt;p&gt;Have you ever tried speaking a new language? It’s hard right? To make it worse, there’s few opportunities to practice. You need to find a fluent speaker to practice with or spend a lot of money to hire a tutor. That’s why we’re dedicated to providing a platform for everyone to practice speaking new languages for free.&lt;/p&gt;

&lt;p&gt;We are a language learning community to help you practice with other people in virtual worlds. We have introduced a credit system, called TBucks, which allows you to gain credits by helping others practice speaking in your native language. You can then use those credits to practice a new language you want to learn.&lt;/p&gt;

&lt;p&gt;You can try it out &lt;a href=&quot;https://github.com/SCP650/Vrlingo-New&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/mgdhqsrxNBY&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;free-language-practice&quot;&gt;Free Language Practice&lt;/h2&gt;

&lt;p&gt;We strive to create a community where each user not only learns a new language, but also acts as a teacher to assist others with their native language. After specifying the languages they know and wish to learn, we provide a live map of all current instances where those specified languages are being spoken. Users can then choose to join as a teacher to earn TBucks or as a student to spend them. This fosters a language learning community and allows for free practice opportunities for speaking.&lt;/p&gt;

&lt;h2 id=&quot;why-vr&quot;&gt;Why VR?&lt;/h2&gt;

&lt;p&gt;VR allows us to build situations and an immersive environment for role-playing.&lt;/p&gt;

&lt;p&gt;For example, we built a restaurant world with many interactive props. We noticed that many Mandarin learners will pretend to order food, talk about their favorite dishes, or try to rob the restaurant while speaking in Mandarin. This makes the language speaking fun and mimics real-life situations.&lt;/p&gt;

&lt;p&gt;To take it a step further, we made contextually-driven prompts that provide topics to talk about. For example, when the user picks up some money in the VR restaurant, they will see “Buy some food with money.” This invites a conversation between the user holding the money and other users in the VR restaurant.&lt;/p&gt;

&lt;h2 id=&quot;monetization&quot;&gt;Monetization&lt;/h2&gt;

&lt;p&gt;There are three ways we could monetize in the future.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Ads: We can place immersive ads in the VR world. For example, a branded soda in the restaurant world, or make branded coffee shop as a world for users to practice speaking in.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Professional Tutors: Some users may appreciate professional tutors such as 1:1 lessons in addition to the free community support. Hence, we can offer classes and take a percentage of the fee.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Subscriptions: We can offer a monthly subscription where users can gain additional features such as show hints to pronounce when grabbing objects, special status icons, and remove ads.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;We use Unity and XR Interaction Toolkit to create the app. The multiplayer networking, VOIP, synced variables and avatar sync are created using Normcore.&lt;/p&gt;

&lt;p&gt;We made this app in 2 days and won the Best Shared World Experience Award at MIT Reality Hack!&lt;/p&gt;

&lt;p&gt;PS: We created the icon of this page using Stable Diffusion.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><category term="Game_Development" /><category term="Product_Project_Management" /><summary type="html">Have you ever tried speaking a new language? It’s hard right? To make it worse, there’s few opportunities to practice. You need to find a fluent speaker to practice with or spend a lot of money to hire a tutor. That’s why we’re dedicated to providing a platform for everyone to practice speaking new languages for free.</summary></entry><entry><title type="html">Match-3 Siege</title><link href="http://localhost:4000/projects/2022/winter/Match3Shooter" rel="alternate" type="text/html" title="Match-3 Siege" /><published>2022-12-30T01:40:23-08:00</published><updated>2022-12-30T01:40:23-08:00</updated><id>http://localhost:4000/projects/2022/winter/Match3Shooter</id><content type="html" xml:base="http://localhost:4000/projects/2022/winter/Match3Shooter">&lt;p&gt;What would Candy Crush + Call of Duty look like?&lt;/p&gt;

&lt;p&gt;Many innovations in video games come from blending genres – what happens if we combine the most popular genre on mobile (match-3) with the most popular genre on PC (shooter)?&lt;/p&gt;

&lt;p&gt;Introducing Match-3 Siege! You can download the demo &lt;a href=&quot;https://github.com/SCP650/Match3Shooter-Unreal5/releases/tag/v1&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-does-it-work&quot;&gt;How does it work?&lt;/h2&gt;

&lt;p&gt;In this game, you’ll be part of either the attacking or defending team. The attackers must destroy all of the colored spheres on the field, while the defenders must protect them.&lt;/p&gt;

&lt;p&gt;To destroy the spheres, attackers must shoot and match three or more of the same color, while fighting against the defenders’ fire.&lt;/p&gt;

&lt;p&gt;To defend the spheres, the defenders need to find and guard strategic positions to prevent match-3 combinations from occurring (e.g. blue blue red blue) and insert new spheres into the field every 30 seconds to make it harder for the attackers (e.g. blue yellow blue red blue).&lt;/p&gt;

&lt;p&gt;If the attackers succeed in destroying all the spheres before time runs out, they win. If any spheres remain, the defenders win.&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/saNxsox4Wz8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The video above is a single-player demo I made for this idea. Although it’s against AI, you can already feel the intense and fast-paced adrenaline rush caused by constantly switching between playing match-3 and fighting against enemies.&lt;/p&gt;

&lt;p&gt;I think this game mode could be added alongside team deathmatch, search and destroy, and battle royal. Let me know what you think!&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This game was made independently by me using Unreal Engine 5.1 and C++. It is my first time making Unreal games with C++ and it has been a great learning experience. I used free 3D and animation assets and implemented the following features:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Animation blending using blendspace&lt;/li&gt;
  &lt;li&gt;Input mapping for locomotion&lt;/li&gt;
  &lt;li&gt;AI behavior tree and blackboard for enemies&lt;/li&gt;
  &lt;li&gt;Integration of particles and sound for shooting&lt;/li&gt;
  &lt;li&gt;Lose and win conditions&lt;/li&gt;
  &lt;li&gt;Match-3 system with chaos destruction.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PS: I created the icon of this page using Stable Diffusion and the text of this page using ChatGPT&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="Game_Development" /><summary type="html">What would Candy Crush + Call of Duty look like?</summary></entry><entry><title type="html">A Second Person VR Game</title><link href="http://localhost:4000/projects/2022/fall/SecondPerson" rel="alternate" type="text/html" title="A Second Person VR Game" /><published>2022-11-26T21:40:23-08:00</published><updated>2022-11-26T21:40:23-08:00</updated><id>http://localhost:4000/projects/2022/fall/SecondPerson</id><content type="html" xml:base="http://localhost:4000/projects/2022/fall/SecondPerson">&lt;p&gt;Have you ever played a second-person multiplayer VR shooting game? Me neither, so I made one over the Thanksgiving break.&lt;/p&gt;

&lt;p&gt;Well, we first need to figure out what is a second-person game.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In a first-person game, you control yourself through your own perspective – I’m going left, I’m going right.&lt;/li&gt;
  &lt;li&gt;In a third-person game, you control yourself through an external perspective – They go left, they go right.&lt;/li&gt;
  &lt;li&gt;So naturally, in a second-person game, you control yourself through the perspective of another character – You go left, you go right.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this game, there are two players and two guns on the table. The goal is very simple: whoever picks up the gun and shoots the other player first wins. But there’s one catch: it’s a second-person game – you are controlling yourself through the perspective of your opponent.&lt;/p&gt;

&lt;p&gt;What does that actually mean? In this clip, it may look like a normal first-person game but you are not controlling yourself – if you raise your VR controller, the character in front of you will raise their hand, not the character you are in the perspective of.&lt;/p&gt;

&lt;p&gt;Originally I thought this would be as if I’m controlling myself through a mirror, but in reality, it is much worse …&lt;/p&gt;

&lt;p&gt;You can try it out &lt;a href=&quot;https://github.com/SCP650/SecondPersonVRGame/releases/tag/v1&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/fCkHKXO1GiU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;main-takeaways&quot;&gt;Main Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;1-true-second-person-vr-games-are-bad&quot;&gt;1. True Second Person VR Games are BAD&lt;/h3&gt;

&lt;p&gt;To make a true second-person game meant you cannot control the camera, since the camera is technically on the head of another character who you don’t control – you just happen to look out from their perspective.&lt;/p&gt;

&lt;p&gt;What that means for VR is that when you move your head to look right, the view you are seeing is not moving, instead, you have to ask the other player to move their head to look right so that you can see what’s on the right.&lt;/p&gt;

&lt;p&gt;This also means if the other player moves their head randomly, their view is not going to be impacted (since your head is not moving), but your view will move randomly causing vertigo and dizziness.&lt;/p&gt;

&lt;h3 id=&quot;2-a-compatitive-game-become-cooperative-quickly&quot;&gt;2. A Compatitive Game Become Cooperative Quickly&lt;/h3&gt;

&lt;p&gt;Even though the goal of the game is to kill the other player, we quickly realize it’s not playable if we don’t cooperate.&lt;/p&gt;

&lt;p&gt;In the video, you can see we struggle to get our own character inside our view. This is because:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Player A can only see stuff from Player B’s perspective. So A needs to give B instructions to adjust A’s view.&lt;/li&gt;
  &lt;li&gt;But B doesn’t know what A is seeing (B can only see A’s perspective), so B doesn’t know many degrees they need to turn.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hence we end up spending the majority of the play time telling the other party how to move their head – “Can you look right?”,”Can you look left?” – which I guess makes this a successful second-person game..? but not an enjoyable game.&lt;/p&gt;

&lt;h3 id=&quot;3-player-will-instinctively-move-their-head-to-adjust-the-camera&quot;&gt;3. Player Will Instinctively Move Their Head to Adjust the Camera&lt;/h3&gt;

&lt;p&gt;One added difficulty I wasn’t expecting before was that when A wants to look left, A will not only give instructions to B to look left but also instinctively move their head to the left – this means it’s also disrupting B’s view.&lt;/p&gt;

&lt;p&gt;And then B’s view is disrupted, B will instinctively move their head in the opposite direction, further disrupting A’s view. This would create a compound effect what gets worse very quickly…&lt;/p&gt;

&lt;h2 id=&quot;some-thoughts&quot;&gt;Some Thoughts…&lt;/h2&gt;

&lt;p&gt;I started this project knowing a second-person VR game would be a bad idea. But my main goal is to figure out how to network a VR game, and I did end up with a multiplayer VR game so I consider this a success!&lt;/p&gt;

&lt;p&gt;Nonetheless, let this serve as a lesson to whoever comes after me that wants to make a second-person VR game. Unless you want to make major sacrifices (like in Trover Saves the Universe), a true second-person game is not a good idea.&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This is made independently by me with &lt;a href=&quot;https://assetstore.unity.com/packages/3d/props/interior/polygon-dining-room-199435&quot;&gt;free 3D assets&lt;/a&gt; from Asset Store, the Oculus Plugin, and the BNG Interaction Framework. It is networked using Normcore. This app is made in Unity with Oculus Quest 2. It can also run on a windows machine with Oculus Link.&lt;/p&gt;

&lt;p&gt;PS: I created the icon of this page using text to image AI.&lt;/p&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><category term="Game_Development" /><summary type="html">Have you ever played a second-person multiplayer VR shooting game? Me neither, so I made one over the Thanksgiving break.</summary></entry><entry><title type="html">Earf</title><link href="http://localhost:4000/projects/2022/summer/earf" rel="alternate" type="text/html" title="Earf" /><published>2022-08-20T22:40:23-07:00</published><updated>2022-08-20T22:40:23-07:00</updated><id>http://localhost:4000/projects/2022/summer/earf</id><content type="html" xml:base="http://localhost:4000/projects/2022/summer/earf">&lt;p&gt;Enjoying pictures of Earth? Why not try Earf – the AR Planet Generator!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tap on the screen to generate gorgeous planets&lt;/li&gt;
  &lt;li&gt;Move your device around to view them up close&lt;/li&gt;
  &lt;li&gt;Simulate physics to see planets collide!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To download the full app: &lt;a href=&quot;https://apps.apple.com/us/app/earf-ar-planets/id1641207075&quot;&gt;Apple App Store&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/UuTJdkB-cac&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;under-the-hood&quot;&gt;Under the Hood&lt;/h2&gt;

&lt;p&gt;This app is made with Unity using AR Foundation. Each terrains is procedurally genearted using multiple layers of perlin noise. A custom shader is made to coloring the planets with random gradients based on the distance of each vertex to the center. It simulations physically (sorta) accurate gravitational force. And also has a random name generator to give your pet planets names!&lt;/p&gt;

&lt;h2 id=&quot;how-was-it-made&quot;&gt;How was it made?&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p1.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p1.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Starting with a blob&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p2.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p2.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Make it round&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p3.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p3.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Sprinkle some perlin noise&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p4.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p4.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Clamp the noise to make ocean surface&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p5.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p5.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Paint the mountains with a shader&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p6.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p6.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Paint the planet with a shader&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p7.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p7.png&quot; alt=&quot;&quot; class=&quot; w-75 text-center &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Paint the ocean depths with a shader&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/earf/p8.png&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/earf/p8.png&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Done!&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;</content><author><name></name></author><category term="All" /><category term="AR_VR" /><category term="Software_Engineer" /><summary type="html">Enjoying pictures of Earth? Why not try Earf – the AR Planet Generator!</summary></entry><entry><title type="html">Siggraph 2022 Day 2</title><link href="http://localhost:4000/blogs/2022/summer/Siggraph22_Part2" rel="alternate" type="text/html" title="Siggraph 2022 Day 2" /><published>2022-08-12T07:40:23-07:00</published><updated>2022-08-12T07:40:23-07:00</updated><id>http://localhost:4000/blogs/2022/summer/Siggraph22_Part2</id><content type="html" xml:base="http://localhost:4000/blogs/2022/summer/Siggraph22_Part2">&lt;p&gt;Hi all, welcome to my Siggraph series where I post the TLDR of the most memorable stuff I see at the conference.&lt;/p&gt;

&lt;p&gt;This started as some rambling notes I took during the conference, and I just cleaned it up a bit. It may not be the most accurate (especially the technical papers) but feel free to take a look!&lt;/p&gt;

&lt;h2 id=&quot;day-2-events-ive-attended&quot;&gt;Day 2 Events I’ve attended:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Tech Papers: &lt;strong&gt;Ray Tracing &amp;amp; Monte Carlo Methods&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Expo: &lt;strong&gt;Emerging Technologies&lt;/strong&gt; + &lt;strong&gt;Immersive Pavilion&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Presentation: &lt;strong&gt;Advances in Real-Time Rendering in Games: Part II&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Expo: Companies&lt;/li&gt;
  &lt;li&gt;Unreal Talk: &lt;strong&gt;Animating In-Engine - Real-Time Production Workflows&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Expo: Appy Hour&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;highlights&quot;&gt;Highlights&lt;/h2&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;immersive-pavilion&quot;&gt;Immersive Pavilion&lt;/h2&gt;

&lt;h3 id=&quot;a-vr-locomotion-method-that-kinda-solves-motion-sickness&quot;&gt;A VR Locomotion Method that (kinda) Solves Motion Sickness&lt;/h3&gt;

&lt;p&gt;What is it: The demo is called “&lt;strong&gt;HyperJumping&lt;/strong&gt;” by Bernhard E. Riecke. It has two parts: lean based locomotion and hyperjump.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lean-Based Locomotion&lt;/strong&gt;: instead of pushing a thumbstick, you have to physically lean forward to move forward. Since your body is actually leaning forward as your visual changes, it’s less dizzy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hyperjump&lt;/strong&gt;: when the user reached a max speed, it will automatically teleport the user for a segment, and then the user will continue to travel at max speed.&lt;/p&gt;

&lt;p&gt;Use case: if a person wants to travel long distances in VR, they don’t want to use smooth locomotion (which is dizzy) and don’t want to teleport (since they will miss the view), they will use lean-based movement + hyperjump.&lt;/p&gt;

&lt;p&gt;Sebastian’s Review: conceptually this is a very interesting idea — combining physical movement with smooth locomotion and teleportation, but in practice, when I tried the demo the Hyperjump(teleportation) feels scary — I would suddenly teleport to another place without any warning. I really like the idea and think further exploration is required.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;expo-companies&quot;&gt;Expo: Companies&lt;/h2&gt;

&lt;p&gt;I tried a ton of demos at the expo, these are the top most memorable three&lt;/p&gt;

&lt;h3 id=&quot;omniverse&quot;&gt;Omniverse&lt;/h3&gt;

&lt;p&gt;I was really really shocked when I saw a live demo of Nvidia’s Omniverse. The demo showcases a game development workflow of 3 people, using Maya, Unreal and Adobe Substance 3D respectively on their own laptops.&lt;/p&gt;

&lt;p&gt;With Omniverse, everything is synced in real-time bi-directionally: if a new car is added in Unreal’s scene, it will be reflected in Maya and Substance 3D instantly. Then the artist in Substance 3D will pain the car, the texture will show up instantly in Unreal and Maya.&lt;/p&gt;

&lt;p&gt;This workflow is very magical and can drastically increase a team’s collaboration efficiency. Under the hood, everything works because they are using Disney’s new and open Universal Scene Description (USD) format. 
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;image-wrapper text-center&quot;&gt;
    
      &lt;a href=&quot; /images/projects/siggraph22/omniverse.jpg&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;
    
        &lt;img src=&quot; /images/projects/siggraph22/omniverse.jpg&quot; alt=&quot;&quot; class=&quot; w-100 &quot; /&gt;

    &lt;/a&gt;
    
        &lt;p&gt;Omniverse Integarting 3 Different Workflow&lt;/p&gt;
    


&lt;/div&gt;

&lt;!-- source from https://superdevresources.com/image-caption-jekyll/ --&gt;

&lt;h3 id=&quot;oppo-air-glass&quot;&gt;Oppo Air glass&lt;/h3&gt;

&lt;p&gt;I tried Oppo’s Air glass, which is an extension screen you can attach to any glasses. It can display information like weather, messages and live translation.&lt;/p&gt;

&lt;p&gt;In theory, it sounds very good, but when I tried it in practice, I need to constantly change my eye focus between the glass and the person I’m talking to in real life which result in fatigue very quickly. The major issue is that the info is not spatialized. Having a screen that constantly displays irrelevant info is also distracting. It’s a good tech demo but would need a lot more improvement to be consume-ready.&lt;/p&gt;

&lt;h3 id=&quot;stretchsense-gloves&quot;&gt;StretchSense Gloves&lt;/h3&gt;

&lt;p&gt;A current problem with optical hand tracking is that if the hand is obstructed, it can’t be tracked. StretchSense gloves managed to imbed a lot of senses in a normal looking glove, and send rotational information from each joint to their software, which will then convert the data to Unity/Unreal supported format.&lt;/p&gt;

&lt;p&gt;On the update, the glove feels comfortable and does hand tracking very feel. But it comes at a hefty~$5k. It’s a good mocap solution and for research use, but probably not for consumer tech.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;animating-in-engine---real-time-production-workflows&quot;&gt;Animating In-Engine - Real-Time Production Workflows&lt;/h2&gt;

&lt;p&gt;The folks at Epic Games showcased how you can create animations in-engineer without the need for professional software like Maya.&lt;/p&gt;

&lt;p&gt;In the demo, the speaker is able to copy parts of one animation (jumping) and paste them to another animation (moving forward), the final result is a person hopping forward.&lt;/p&gt;

&lt;p&gt;This is very impressive in that programmers can just download a few free mocap assets, and cut and paste different portions to combine to the desired motions. This makes prototyping ideas and making short video clips so much faster.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;tech-papers-ray-tracing--monte-carlo-methods&quot;&gt;Tech Papers: Ray Tracing &amp;amp; Monte Carlo Methods&lt;/h2&gt;

&lt;h3 id=&quot;r2e2-low-latency-path-tracing-of-terabyte-scale-scenes-using-thousands-of-cloud-cpus&quot;&gt;R2E2: Low-latency Path Tracing of Terabyte-scale Scenes Using Thousands of Cloud CPUs&lt;/h3&gt;

&lt;p&gt;Problem: if you need to render terabyte-scale scenes, and you don’t happen to own a super computer… you are out of luck&lt;/p&gt;

&lt;p&gt;Solution: Why now rent thousands of CPUs to run at the same time? That’s what the author did, live, at the presentation — he rented thousands of AWS E3 instances and rendered a path-traced picture of a terabyte scene in ~1 mins.&lt;/p&gt;

&lt;h3 id=&quot;generalized-resampled-importance-sampling-foundations-of-restir&quot;&gt;Generalized Resampled Importance Sampling: Foundations of ReSTIR&lt;/h3&gt;

&lt;p&gt;Problem: Traditional ray tracing is very costly and slow, it also requires multiple passes to generate a good image.&lt;/p&gt;

&lt;p&gt;Context: The ReSTIR approach - it reuses samples from previous frames to improve path distributions across frames (temporal reuse) and resample between this and nearby pixels (spatial reuse)&lt;/p&gt;

&lt;p&gt;Solution: Through some cool math and magic that I don’t fully understand, the author generalized the ReSTIR approach to work on any domains without the need to know the exact PDF&lt;/p&gt;

&lt;h3 id=&quot;regression-based-monte-carlo-integration&quot;&gt;Regression-based Monte Carlo Integration&lt;/h3&gt;

&lt;p&gt;Problem: Solving integration is a hard but common problem in graphics, e.g. to light up one pixel properly, we need to calculate the integral of all the light paths connecting the pixel to the light source.&lt;/p&gt;

&lt;p&gt;Context: Currently we mostly use Monte Carlo Integration, which randomly samples the function and averages those values to estimate the integral. However, this is only an estimate and has errors.&lt;/p&gt;

&lt;p&gt;Solutions: the author proposes a new estimator using regression function + residual, this estimator is provable better than Monte Carlo. Because in the worst case, the regression will be a constant, which will produce the same result as Monte Carlo.&lt;/p&gt;</content><author><name></name></author><summary type="html">Hi all, welcome to my Siggraph series where I post the TLDR of the most memorable stuff I see at the conference.</summary></entry></feed>